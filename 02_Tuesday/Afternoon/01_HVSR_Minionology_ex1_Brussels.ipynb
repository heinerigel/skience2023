{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f34b8d",
   "metadata": {},
   "source": [
    "# Minionology: HVSR with seismic nodes\n",
    "### Skience2023 practical on HVSR, node installation, applications, Geopsy, continuous data analysis\n",
    "\n",
    "##### Authors:\n",
    "* Koen Van Noten ([@KoenVanNoten](https://github.com/KoenVanNoten))\n",
    "* Thomas Lecocq ([@seismotom](https://github.com/ThomasLecocq)\n",
    "\n",
    "##### Introduction:\n",
    "Three-component __seismic nodes__ are conquering the world these days as lightweight smart seismic sensors. This notebook is a simple introduction how to handle seismic node data and perform H/V spectral ratio analysis of ambient noise (mHVSR) recorded with seismic nodes. We'll show you some methods:\n",
    "* how to perform mHVSR using the Geopsy software manually\n",
    "* how to do the same exercise automatically \n",
    "* and we'll open the discussion towards more automatic solutions given by the Skience2013 crowd. \n",
    "\n",
    "SmartSolo 3D Nodes (https://smartsolo.com/cp.php?id=3) are easy to deploy, have long battery life (2-4 weeks), are modular to easily replace battery and are fastly charged. The picture below shows the modular design of the IGU-16HR 3C series where 3C sensors are installed on a standard battery pack (usually used with the 1C nodes). The tripod feet allow them to be used in urban settings. As they resemble to the Minions, we batised _data analysis with nodes_ as __Minionology__. We further refer to Zeckra et al. (submitted) to a technical introduction on the performance of the IGU-16HR 3C series. \n",
    "\n",
    "##### References:\n",
    "* Van Noten, K., Lecocq, T., Goffin, C., Meyvis, B., Molron, J., Debacker, T.N. & Devleeschouwer, X. 2022. Brussels’ bedrock paleorelief from borehole-controlled powerlaws linking polarised H/V resonance frequencies and sediment thickness. _Journal of Seismology_ 26, 35-55. DOI: https://doi.org/10.1007/s10950-021-10039-8 pdf: https://publi2-as.oma.be/record/5626/files/2022_VanNotenetal_HVSR_Powerlaw_Brussels.pdf \n",
    "* Van Noten, K, Lecocq, Buddha Power, B. (2020). HVSR to Virtual Borehole (1.0). Zenodo. https://doi.org/10.5281/zenodo.4276310\n",
    "* Zeckra, M., Van Noten, K., Lecocq, T. Submitted. Sensitivity, Accuracy and Limits of the Lightweight Three-Component SmartSolo Geophone Sensor (5 Hz) for Seismological Applications. _Seismica_. Preprint on: https://doi.org/10.31223/X5F073\n",
    "\n",
    "<img src=\"Figures/Minions Seismology.be.jpg\" width=600></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634f4a8",
   "metadata": {},
   "source": [
    "## Exercise 1:  \n",
    "## The Paleotopography of the Brabant Massif (bedrock) below Brussels\n",
    "In the first exercise, we will analyse a dataset recorded in Brussels (Belgium) during a busy Friday in November 2022. Purpose of this data recording is to analyse the variation in (seismic) bedrock depth along a long profile taken in the Tour et Taxis site. In Brussels, many buildings are interested in installing a shallow geothermal well to heat/cool te building. In the city many shallow systems are installed that exploit aquifers in Cenozoic, soft sediment layers. However, the bedrock (London-Brabant Massif) may be as well suitable for geothermal heating/cooling. Our purpose as geophysicist/seismologist is to predict the variation of bedrock depth below buildings using non-destructive ambient noise techniques, which can be implemented in 3D geological models or can be used in a tender towards a drilling company.  \n",
    "\n",
    "<img src=\"Figures/TouretTaxis_Brussels.png\" width=1200></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d96655",
   "metadata": {},
   "source": [
    "### Let's start\n",
    "Activate the necessary modules and run the 00_HVSR_Minionology_definitions.ipynb notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bcf9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import obspy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections as mcoll\n",
    "import matplotlib.gridspec as gridspec\n",
    "from obspy.imaging.scripts.scan import Scanner\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# run the HVSR Minionology function notebook\n",
    "%run 00_HVSR_Minionology_definitions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ed5f8",
   "metadata": {},
   "source": [
    "The seismic dataset gathered at the Tour et Taxis site in Brussels can be downloaded here:\n",
    "__TO DO__\n",
    "\n",
    "Before playing with the HVSR data, let's have a look on data gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217817e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner = Scanner()\n",
    "scanner.parse(\"HVSR_ex1_Bru\")  \n",
    "scanner.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a60c52",
   "metadata": {},
   "source": [
    "### 1. Geopsy HVSR dataprocessing\n",
    "Before processing any data we need perform a manual data analysis in Geopsy first. Download Geopsy from here (https://www.geopsy.org/download.php) and choose your proper platform (Windows, Mac, Linux). Credits to Marc Wathelet & team (ISTerre Grenoble) for years of Geopsy coding, development and improvement. \n",
    "\n",
    "We will first manually process the seismic data in Geopsy using the _HV module_ and following standard processing steps. In the Geopsy H/V module use following parameters (also explained here: https://www.geopsy.org/wiki/index.php/H/V_spectral_ratio)\n",
    "* __Length__: 120s\n",
    "* __Overlap__: 50%\n",
    "* __Relative treshhold__: 70%\n",
    "* __Taper__: 5% Tukey\n",
    "* __Konno-Omachi smoothing__: 40%\n",
    "* __Squared Average__\n",
    "* __Output__: 0.20Hz - 50 Hz\n",
    "* __Step Count__: 500\n",
    "\n",
    "After computation, manually clean the H/V curve by _Reject time windows_ (right click on the graph) and select those curves that deviate from the mean curve. Then recompute the H/V curve by pressing the black arrow next to _select_ -> _clear_ -> _Remove grayed_ and press _Start_ again.\n",
    "\n",
    "To save the .HV results do a _Tools_ -> _Save Results_ and save it in the  __HVSR_ex1_Bru\\Analysed__ folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c86af",
   "metadata": {},
   "source": [
    "### 2. Geopsy .hv data reading and plotting\n",
    "For each node, an .hv file was created using Geopsy. An .hv file contains the values of :\n",
    "* the \"Frequency\" versus mean \"H/V Amplitude\"=\"Average\" values \n",
    "* the standard deviation of the HV curve expressed by \"Min\" and \"Max\" amplitude\n",
    "\n",
    "It is easy first to have a look to one .HV file in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the HV data. Use the read_HV function.\n",
    "#read_HV?\n",
    "\n",
    "HV_file = r'HVSR_ex1_Bru\\Analysed\\BE_00039.hv'\n",
    "Freq, A, A_min, A_max = read_HV(HV_file)\n",
    "print(Freq.head(), A.head(), A_min.head(), A_max.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a369372",
   "metadata": {},
   "source": [
    "* Plot the A0 vs Freq HV curve. \n",
    "* Add the error on f0 using a _fill_betweenx_ function\n",
    "* Scatterplot the f0 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the HV plot\n",
    "fig, ax= plt.subplots(figsize=(10,5))\n",
    "plt.plot(A, Freq, label='$f_0$ average')\n",
    "plt.fill_betweenx(Freq, A_min,A_max,facecolor=\"silver\", edgecolor=\"k\", alpha=0.3, label = 'error')\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('H/V amplitude', fontsize = 14)\n",
    "plt.ylabel('Frequency ([Hz])', fontsize = 14)\n",
    "plt.legend()\n",
    "plt.title(os.path.splitext(os.path.split(HV_file)[1])[0], fontsize = 14)\n",
    "plt.grid(ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d01ea",
   "metadata": {},
   "source": [
    "Find the resonance frequency (f0) and its H/V amplitude (A0) from the HV data using the get_params_from_HV_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fe950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_params_from_HV_curve?\n",
    "f0_curve, A0_curve, A0_min_curve, A0_max_curve = get_params_from_HV_curve(HV_file)\n",
    "print(f0_curve, A0_curve, A0_min_curve, A0_max_curve)\n",
    "print('At %s Hz (f0), the maximum H/V amplitude is %s ± %s'%(round(f0_curve,2), round(A0_curve,1), round(A0_max_curve-A0_curve,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8767f312",
   "metadata": {},
   "source": [
    "You also can load the information directly from the .hv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_params_from_HV?\n",
    "f0_avg, f0_win, error, A0, nw_avg, nw_win, f_min, f_max = get_params_from_HV(HV_file)\n",
    "print(f0_avg, f0_win, error, A0, nw_avg, nw_win, f_min, f_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036dafc",
   "metadata": {},
   "source": [
    "Sometimes there are multiple peaks in the HV curve. Optionally, we can search for the maximum in the HV curve in a specific frequency range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_params_from_partial_HV_curve?\n",
    "f_range, A_range, A_min_range, A_max_range = get_params_from_partial_HV_curve(HV_file, 20 , 100)\n",
    "f_range, A_range, A_min_range, A_max_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4346e",
   "metadata": {},
   "source": [
    "__Now do it all at once:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2db1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HV_file = r'HVSR_ex1_Bru\\Analysed\\BE_00039.hv'\n",
    "\n",
    "# create the plot\n",
    "fig, ax= plt.subplots(figsize=(10,5))\n",
    "\n",
    "# get the HV values and plot\n",
    "Freq, A, A_min, A_max = read_HV(HV_file)\n",
    "plot_HV(Freq, A, A_min, A_max, f0_curve, A0_curve,  A0_min_curve, A0_max_curve, 'manual', 'blue')\n",
    "\n",
    "# get the values from the curve and scatterplot\n",
    "f0_curve, A0_curve, A0_min_curve, A0_max_curve = get_params_from_HV_curve(HV_file)\n",
    "plt.scatter(A0_curve, f0_curve, c = 'red', edgecolors = 'grey', alpha = 0.8, zorder = 10, \n",
    "            label='$f_0$: %s Hz \\n$A_0$: %s'%(round(f0_curve,2), round(A0_curve,1)))\n",
    "\n",
    "# or get the values from the .hv file and scatterplot\n",
    "f0_avg, f0_win, error, A0, nw_avg, nw_win, f_min, f_max = get_params_from_HV(HV_file)\n",
    "plt.scatter(A0, f0_win, c = 'green', edgecolors = 'grey', alpha = 0.8, zorder = 10, \n",
    "            label='$f_0$: %s Hz \\n$A_0$: %s'%(round(f0_curve,2), round(A0_curve,1)))\n",
    "\n",
    "# or get the values from a partial part of the HV curve and scatterplot\n",
    "f_range, A_range, A_min_range, A_max_range = get_params_from_partial_HV_curve(HV_file, 20 , 100)\n",
    "plt.scatter(A_range, f_range, c = 'blue', edgecolors = 'grey', alpha = 0.8, zorder = 10, \n",
    "            label='$f_0$: %s Hz \\n$A_0$: %s'%(round(f_range,2), round(A_range,1)))\n",
    "\n",
    "plt.title(os.path.splitext(os.path.split(HV_file)[1])[0], fontsize = 14)\n",
    "plt.grid(ls='--')\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('H/V amplitude', fontsize = 14)\n",
    "plt.ylabel('Frequency ([Hz])', fontsize = 14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878b25d",
   "metadata": {},
   "source": [
    "We can now convert the whole HV curve to a __Virtual Borehole__ if the velocity of the soft sediment is known. A virtual borehole is usefull to communicate to general public/geologists etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HV_to_virtual_borehole?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ba428",
   "metadata": {},
   "outputs": [],
   "source": [
    "HV_file = r'HVSR_ex1_Bru\\Analysed\\BE_00270.hv'\n",
    "Z = 100 # altitude of the measurement\n",
    "\n",
    "# Figure savefolder\n",
    "out_folder = 'Figures'\n",
    "\n",
    "# Choose if you want to use the Geopsy exported values or want to interpolate between 0 and 15000 frequency values\n",
    "# See annotations in \"get_interpolated_values_from_HV for details\n",
    "interpolate = False\n",
    "\n",
    "# Choose if the amplitude on the frequency-amplitude plot needs to be selected automatically or manually\n",
    "auto_amplitude = False\n",
    "manual_amplitude = 15\n",
    "\n",
    "# Choose between which frequencies you want to plot. Default = between 0.5 Hz and 50 Hz\n",
    "freq = [0.5, 50]\n",
    "\n",
    "## f0 needs to be converted to depth by: \n",
    "## e.g. using a Powerlaw relation between resonance frequency and depth according to the formula: depth = a * power(f0, b)\n",
    "## a & b values of the Regional powerlaw relation (R') of Van Noten et al. 2022.\n",
    "depth_conversion = 'powerlaw'\n",
    "a_pw = 88.631     # a value\n",
    "b_pw = -1.683    # b value\n",
    "\n",
    "## or by using a fixed velocity\n",
    "# depth_conversion = 'Vs'\n",
    "# Vs = 400 # m/s\n",
    "\n",
    "# apply the function\n",
    "ID = os.path.split(HV_file)[1].split('.')[0]\n",
    "HV_to_virtual_borehole(HV_file, ID, Z)\n",
    "\n",
    "#save it by node name\n",
    "ID = os.path.split(HV_file)[1].split('.')[0]\n",
    "savefile = os.path.join(out_folder, '%s_VB.png'%ID)\n",
    "plt.savefig(savefile, format= 'png', dpi = 300)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e2ba9",
   "metadata": {},
   "source": [
    "### 3. Reading the HVSR database file\n",
    "All the node metadata information has been preloaded in an HVSR database file. The HVSR database file is available in the __HVSR_ex1_Bru__ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11763eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HV_database = r'HVSR_ex1_Bru\\HVSR_database_TouretTaxis.csv'\n",
    "HV_db_folder, HV_db_name = os.path.split(HV_database)[0], os.path.split(HV_database)[1]\n",
    "print(HV_db_folder)\n",
    "print(HV_db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a15a46",
   "metadata": {},
   "source": [
    "Load the HVSR database into a pandas database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_HVSR = pd.read_csv(HV_database, encoding='latin')\n",
    "db_HVSR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8665a3a",
   "metadata": {},
   "source": [
    "Compute the distance of each node to the first node using the Obspy _obspy.geodetics.base.gps2dist_azimuth_ function and load it to an array.  \n",
    "\n",
    "inter_distance = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bcf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.geodetics.base import gps2dist_azimuth \n",
    "# gps2dist_azimuth? Obspy info\n",
    "\n",
    "lat = db_HVSR['Lat']\n",
    "lon = db_HVSR['Lon']\n",
    "\n",
    "inter_distances = []\n",
    "for nr in np.arange(0,len(db_HVSR)-1,1):\n",
    "    inter_distances.append(gps2dist_azimuth(lat[nr], lon[nr], lat[nr+1],lon[nr+1])[0])\n",
    "inter_distances = pd.Series(inter_distances)\n",
    "inter_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c120a0",
   "metadata": {},
   "source": [
    "To later plot the HV profiles with distance, create a cumulative distance series (d_cumul) with _pd.series.cumsum()_\n",
    "\n",
    "Add a [0] as first distance with pd.concat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c786f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# open a series, but start with distance 0\n",
    "cumul = pd.Series([0])\n",
    "# add the cumulative distances to the cumul list\n",
    "d_cumul = pd.concat([cumul,inter_distances.cumsum()], ignore_index = True)\n",
    "d_cumul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ccb4d1",
   "metadata": {},
   "source": [
    "Add the cumulative distance column to the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_HVSR['d_cumul'] = d_cumul\n",
    "db_HVSR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b3b0b",
   "metadata": {},
   "source": [
    "### 4. Filling the HVSR database file with .hv data\n",
    "\n",
    "By using Geopsy, the HVSR data has been saved as .hv files in the _HVSR_ex1_Bru\\Analysed_ folder. We will extract and add it to the HVSR database. The script in below (Van Noten _et al._ 2022) reads the HVSR database and extracts all the necessary data in the .hv files being:\n",
    "\n",
    "* __f0 min__: f0_win/stddev (from GEOPSY)\n",
    "* __f0_win__: average resonance frequency by taking the f0 of each individual window and averaging all f0 values from these windows (from GEOPSY)\n",
    "* __f0 avg__: scanning the average curve and identifying the frequency at which the maximum amplitude occurs (from GEOPSY)\n",
    "* __f0_ip__: resonance frequency computed after interpolating the HV-Amplitude graph using python. This is useful if you forgot to adapt the Step Count\n",
    "* __f0_ip_diff__: difference between f0_ip and f0_win\n",
    "* __error__: standard deviation on f0 (from GEOPSY)\n",
    "* __f0 max__: f0_win.stddev (from GEOPSY)\n",
    "* __A0__: maximum amplitude (from GEOPSY)\n",
    "* __nw__: number of windows (from GEOPSY)\n",
    "\n",
    "Reference:\n",
    "https://github.com/KoenVanNoten/HVSR_to_virtual_borehole/blob/master/Get%20f0s%20from%20geopsy%20hv%20files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4762a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the database file in which all the names of the .hv measurements are stored\n",
    "HV_folder = os.path.join(HV_db_folder, 'Analysed')  #folder containing all .hv data\n",
    "\n",
    "#### Initializing empty columns that need to be filled from the Geopsy .hv files\n",
    "for _ in [\"f0_min\", \"f0_win\", \"f0_avg\", \"f0_int\", \"f0_int_diff\", \"error\", \"f0_max\", \"A0\", \"nw\"]:\n",
    "    db_HVSR[_] = 0.\n",
    "\n",
    "# specify a name for the HVSR + HV params database\n",
    "out_file = os.path.splitext(HV_db_name)[0] + \"_f0_from_hv.csv\"\n",
    "\n",
    "#### loop through each .hv datafile\n",
    "for id, row in db_HVSR.iterrows():\n",
    "    HV_file = os.path.join(HV_folder, row[\"ID\"] + \".hv\")\n",
    "    print(HV_file)\n",
    "    \n",
    "    # get all params from the HV file\n",
    "    f0_avg, f0_win, error, A0, nw_avg, nw_win, f_min, f_max = get_params_from_HV(HV_file)\n",
    "    \n",
    "    # get interpolated f0 and A0 from the HV file\n",
    "    f0_int, A0_int, f0_int_diff = get_interpolated_values_from_HV(HV_file, 15000, f0_win)\n",
    "\n",
    "    #write all data to the database file\n",
    "    #write_HVline_to_db?\n",
    "    write_HVline_to_db(db_HVSR, f_min, f0_win, f0_avg, f0_int, f0_int_diff, error, f_max, A0, nw_win)\n",
    "\n",
    "\n",
    "db_HVSR.to_csv(os.path.join(HV_db_folder, out_file), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_HVSR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83fced",
   "metadata": {},
   "source": [
    "We can now check how the map looks like and color it by whatever parameter you want. e.g. f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the HV plot\n",
    "fig, ax= plt.subplots()\n",
    "#Checking how the profile looks like - Use the Belgian Lambert72 projection column \n",
    "scatter = plt.scatter(db_HVSR['Lambert-X'], db_HVSR['Lambert-Y'], c=db_HVSR['f0_win'],  cmap = 'viridis', label='first node: %s'%(db_HVSR[\"ID\"][0]))\n",
    "cb = plt.colorbar(scatter, orientation='vertical')\n",
    "cb.set_label('Resonance frequency', backgroundcolor = 'white')\n",
    "ax.axis('equal')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb070a",
   "metadata": {},
   "source": [
    "Or plot it in a more interactive way using the python folium module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# APPLY COLOR TO DATASET\n",
    "\n",
    "import folium\n",
    "\n",
    "## todo: link Viridis colors to the db_HVSR['f0_avg'] values, not the order of plotting\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(\"viridis\", len(db_HVSR['f0_win'])).as_hex()\n",
    "palette.reverse()\n",
    "\n",
    "# let's plot\n",
    "m = folium.Map(location=[db_HVSR['Lat'][13], db_HVSR['Lon'][13]], zoom_start=15)\n",
    "\n",
    "for i,j,k,color in zip(db_HVSR['Lat'], db_HVSR['Lon'], db_HVSR['f0_avg'], palette):\n",
    "    folium.CircleMarker([i, j],\n",
    "                 radius = 7,\n",
    "                        color = 'black',\n",
    "                        fill=True,\n",
    "                        fill_color=color,\n",
    "                        fill_opacity=1,\n",
    "                        opacity = 0.5\n",
    "                 ).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcfe26",
   "metadata": {},
   "source": [
    "### 4. Creating an HVSR cross-profile\n",
    "We want to create an HVSR profile showing the variation of resonance frequency along the profile where the nodes where installed. \n",
    "\n",
    "First let's have a look to all HVSR data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot\n",
    "fig, ax= plt.subplots(figsize=(16,6))\n",
    "\n",
    "# We will loop over the HVSR database using pandas groupby to plot each HV profile along the distance. \n",
    "for id, group in db_HVSR.groupby(\"H/V\"):\n",
    "    \n",
    "    # loop over the .hv files\n",
    "    for id,line in group.iterrows():\n",
    "        ID = line.ID + \".hv\"\n",
    "        HV_file = os.path.join(HV_db_folder, 'Analysed', ID)\n",
    "        \n",
    "        ### load necessary data\n",
    "        Freq, A0, A_min, A_max = read_HV(HV_file)\n",
    "        plt.plot(A0, Freq, c='grey', alpha = 0.5)\n",
    "\n",
    "        # scatterplot a dot on f0 and A0      \n",
    "        f0_curve, A0_curve, A0_min_curve, A0_max_curve = get_params_from_HV_curve(HV_file)\n",
    "        plt.scatter(A0_curve, f0_curve, c = 'red', edgecolors = 'red', alpha = 0.5, zorder = 10, \n",
    "            label='$f_0$: %s Hz \\n$A_0$: %s'%(round(f0_curve,2), round(A0_max_curve,1)))\n",
    "        \n",
    "        # or scatterplot a dot on f0 and A0 from the HV file\n",
    "        f0_avg, f0_win, error, A0, nw_avg, nw_win, f_min, f_max = get_params_from_HV(HV_file)\n",
    "        plt.scatter(A0, f0_avg, c = 'red', edgecolors = 'green', alpha = 0.5, zorder = 10 ,\n",
    "                    label='$f_0$: %s Hz \\n$A_0$: %s'%(round(f0_curve,2), round(A0_max_curve,1)))\n",
    "\n",
    "        # or get the values from a partial part of the HV curve and scatterplot\n",
    "        f_range, A_range, A_min_range, A_max_range = get_params_from_partial_HV_curve(HV_file, 10 , 100)\n",
    "        plt.scatter(A_range, f_range, c = 'blue', edgecolors = 'grey', alpha = 0.8, zorder = 10, \n",
    "                    label='$f_0$: %s Hz \\n$A_0$: %s'%(round(f_range,2), round(A_range,1)))\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('H/V amplitude', fontsize = 14)\n",
    "plt.ylabel('Frequency ([Hz])', fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edfa12",
   "metadata": {},
   "source": [
    "Now, let's make the HVSR profile with distance.\n",
    "\n",
    "__Strategy__: this profile is made by\n",
    "* finding the largest amplitude of all HV curves\n",
    "* normalising all amplitudes to this largest amplitude\n",
    "* converting the amplitude to distance (hack-solution) so it can be plotted \n",
    "\n",
    "__Possibilities__:\n",
    "We can either make a \n",
    "* frequency-distance plot to show the HV curve variation\n",
    "or convert the HV curve to depth by using:\n",
    "* a fixed group velocity for the entire soft sediment layer: e.g. Vs = 400 m/s\n",
    "* or using a powerlaw equation between f0 and depth in the form of h = _a_ * np.power(f0,_b_), with _a_ and _b_ fixed parameters set to a certain area (e.g. by performing HVSR above boreholes with known h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b009522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HV_database = r'HVSR_ex1_Bru\\HVSR_database_TouretTaxis_f0_from_hv.csv'\n",
    "db_HVSR = pd.read_csv(HV_database, encoding='latin')\n",
    "\n",
    "### Choose which profile you want: \n",
    "freq_profile = False ## frequency profile of all HVs\n",
    "\n",
    "depth_profile_fixed = True #depth profile with frequency converted to depth with a fixed velocity \n",
    "Vs = 400 #m/s\n",
    "\n",
    "depth_profile_powerlaw = False #depth profile with frequency converted to depth using a powerlaw equation\n",
    "a_pw = 88.631     # a value of the powerlaw\n",
    "b_pw = -1.683    # b value of the powerlaw\n",
    "\n",
    "### Give the exaggeration value to exaggerate the horizontal scale of the HV plots\n",
    "### e.g. h_exa = 1 will give virtual boreholes\n",
    "h_exa = 80\n",
    "\n",
    "#######################\n",
    "## Main program\n",
    "#######################\n",
    "# create plot\n",
    "fig, ax= plt.subplots(figsize=(16,6))\n",
    "\n",
    "# Create empty arrays to get all the HV data\n",
    "Freqs= []\n",
    "A0s = []\n",
    "Amins = []\n",
    "Amaxs = []\n",
    "f0s_db = []\n",
    "A0s_db = []\n",
    "max_amp = 0\n",
    " \n",
    "# loop over the .hv files\n",
    "for id, line in db_HVSR.iterrows():\n",
    "        ID = line.ID + \".hv\"\n",
    "        HV_file = os.path.join(HV_db_folder, 'Analysed', ID)\n",
    "        \n",
    "        ### load necessary data\n",
    "        Freq, A0, A_min, A_max = read_HV(HV_file)\n",
    "        Freqs.append(Freq)\n",
    "        A0s.append(A0)\n",
    "        Amins.append(A_min)\n",
    "        Amaxs.append(A_max)\n",
    "        # get the maximum amplitude of all HV files to normalise the max amplitude later\n",
    "        if A0.max() > max_amp:\n",
    "            max_amp = A0.max()\n",
    "        f0s_db.append(line.f0_avg)\n",
    "        A0s_db.append(line.A0)\n",
    "        \n",
    "# Normalise the amplitudes and min and max (to potentially plot the error on f0)\n",
    "A0s = pd.Series(A0s)/max_amp\n",
    "Amins = pd.Series(Amins)/max_amp\n",
    "Amaxs = pd.Series(Amaxs)/max_amp\n",
    "\n",
    "# create a pandas db for plotting all curves\n",
    "db_HVs = pd.DataFrame({'Freqs':Freqs, 'A0s':A0s, 'Amins':Amins, 'Amaxs':Amaxs, \n",
    "                       'd_cumul':db_HVSR[\"d_cumul\"], 'Z':db_HVSR[\"Z\"]})\n",
    "for k, _ in db_HVs.iterrows():        \n",
    "        # convert amplitudes to distances\n",
    "        arrays = []\n",
    "        for ar in [_.A0s, _.Amins, _.Amaxs]:\n",
    "            ar *= h_exa\n",
    "            ar += _.d_cumul\n",
    "            arrays.append(ar)\n",
    "        # if you want a frequency plot y = frequency values        \n",
    "        if freq_profile:\n",
    "            y = _.Freqs\n",
    "        \n",
    "        # if you want a depth profile with a fixed Vs,  y = Vs / 4*f0            \n",
    "        if depth_profile_fixed:\n",
    "            y = Vs / (_.Freqs * 4)\n",
    "            y= _.Z - y\n",
    "    \n",
    "        # if you want a depth profile with a powerlaw conversion,  y = powerlaw            \n",
    "        if depth_profile_powerlaw:\n",
    "            y = a_pw * np.power(_.Freqs,b_pw)\n",
    "            y= _.Z - y\n",
    "        \n",
    "        # color the lines\n",
    "        colorline(arrays[0], y, _.A0s, cmap='viridis', linewidth=5)\n",
    "        colorbar = colorline(arrays[0], y, _.A0s, cmap='viridis', linewidth=5)        \n",
    "        \n",
    "        # scatterplot a dot on f0 and A0\n",
    "        Amax_f0 = np.max(arrays[0])\n",
    "        Fmax_f0 = y[np.argmax(arrays[0])]\n",
    "        plt.scatter(Amax_f0, Fmax_f0, c = 'red', edgecolors = 'red', alpha = 0.5, zorder = 10)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylim(0.5,100)\n",
    "\n",
    "if freq_profile:\n",
    "        plt.ylabel(\"Frequency [Hz]\",  fontsize=14)\n",
    "        ax.set_yscale('log')\n",
    "else:\n",
    "        plt.ylabel(\"Depth [m]\",  fontsize=14)\n",
    "        plt.ylim(-150,30)\n",
    "\n",
    "plt.xlabel(\"Distance [m] & Normalized Amplitude\",  fontsize=14)\n",
    "id = '%s '%(db_HVSR[\"Comment\"][0].split('_')[0])\n",
    "plt.title('H/V spectral ratio analysis - %s'%id,  fontsize=16)\n",
    "plt.xlim(0,1600)\n",
    "plt.grid()\n",
    "plt.savefig('Figures/HVSR_profile_Brussels.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f985a0",
   "metadata": {},
   "source": [
    "Alternatively, we also can make a virtual borehole for each individual measurement loading each .hv file from the database and save it as a Virtual Borehole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f8658",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ### Load the HVSR data and the database csv overview file from the folder\n",
    "HV_database = r'HVSR_ex1_Bru\\HVSR_database_TouretTaxis_f0_from_hv.csv'\n",
    "\n",
    "# Datafolder with HV files\n",
    "in_folder = 'HVSR_ex1_Bru\\Analysed'\n",
    "\n",
    "# Plot only one Virtual Borehole with the ID given (ID & .hv file need to be in the database file)\n",
    "# If plot_one = 0; all .hv files will be plotted as a Virtual Borehole\n",
    "plot_one = False\n",
    "HV = 'BE_00039'\n",
    "\n",
    "# Choose if you want to use the Geopsy exported values or want to interpolate between 0 and 15000 frequency values\n",
    "# See annotations in \"get_interpolated_values_from_HV for details\n",
    "interpolate = False\n",
    "\n",
    "# Choose if the amplitude on the frequency-amplitude plot needs to be selected automatically or manually\n",
    "auto_amplitude = True\n",
    "manual_amplitude = 20\n",
    "\n",
    "# Choose between which frequencies you want to plot. Default = between 0.5 Hz and 50 Hz\n",
    "freq = [0.5, 50]\n",
    "\n",
    "## f0 needs to be converted to depth by: \n",
    "## e.g. using a Powerlaw relation between resonance frequency and depth according to the formula: depth = a * power(f0, b)\n",
    "## a & b values of the Regional powerlaw relation (R') of Van Noten et al. 2022.\n",
    "depth_conversion = 'powerlaw'\n",
    "a_pw = 88.631     # a value\n",
    "b_pw = -1.683    # b value\n",
    "'''\n",
    "## or by using a fixed velocity\n",
    "depth_conversion = 'Vs'\n",
    "Vs = 400 # m/s\n",
    "'''\n",
    "\n",
    "## wanna and/or save or plot the data?\n",
    "plot = True\n",
    "save = False\n",
    "out_folder = 'Figures'\n",
    "\n",
    "######################################\n",
    "## Run Program\n",
    "######################################\n",
    "\n",
    "# Find filename from ID nr & convert 1 HVSR\n",
    "db_HVSR = pd.read_csv(HV_database, encoding='latin', index_col = 'ID')\n",
    "\n",
    "## Loop over files\n",
    "if plot_one:\n",
    "    Z = db_HVSR.loc[HV].Z\n",
    "    HV_file = os.path.join(in_folder, HV +'.hv')\n",
    "    print (HV_file)\n",
    "    # apply the function\n",
    "    HV_to_virtual_borehole(HV_file, HV, Z)\n",
    "    \n",
    "    if save:\n",
    "        #save it by node name\n",
    "        savefile = os.path.join(out_folder, '%s_VB.png'%HV)\n",
    "        plt.savefig(savefile, format= 'png', dpi = 300)\n",
    "        print('')\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    \n",
    "# plot all HVSR data\n",
    "else:\n",
    "    Z = db_HVSR['Z']\n",
    "    for i,j in zip(db_HVSR.index,Z):\n",
    "        print(i)\n",
    "        HV_file = os.path.join(in_folder, i + '.hv')\n",
    "        HV_to_virtual_borehole(HV_file, i, j)\n",
    "        \n",
    "        if save:\n",
    "            #save it by node name\n",
    "            savefile = os.path.join(out_folder, '%s_VB.png'%i)\n",
    "            plt.savefig(savefile, format= 'png', dpi = 300)\n",
    "            print('')\n",
    "\n",
    "        if plot:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23f37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b70c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149da13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8afdf97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
