{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f34b8d",
   "metadata": {},
   "source": [
    "# Minionology: HVSR with seismic nodes\n",
    "### Skience2023 practical on HVSR, node installation, applications, Geopsy, continuous data analysis\n",
    "\n",
    "##### Authors:\n",
    "* Koen Van Noten ([@KoenVanNoten](https://github.com/KoenVanNoten))\n",
    "* Thomas Lecocq ([@seismotom](https://github.com/ThomasLecocq))\n",
    "* Martin Zeckra ([@marzeck](https://github.com/marzeck))\n",
    "\n",
    "##### Introduction:\n",
    "Geopsy is a powerful software to process ambient noise data. This notebook lists some definitions to read in outputfiles generated by Geopsy.\n",
    "\n",
    "* .hv files are the Geopsy output files after using the HV module: https://www.geopsy.org/wiki/index.php/H/V_spectral_ratio\n",
    "\n",
    "##### References:\n",
    "* Van Noten, K., Devleeschouwer, X., Goffin, C., Meyvis, B., Molron, J., Debacker, T.N. & Lecocq, T. 2022. Brusselsâ€™ bedrock paleorelief from borehole-controlled powerlaws linking polarised H/V resonance frequencies and sediment thickness. _Journal of Seismology_ 26, 35-55. DOI: https://doi.org/10.1007/s10950-021-10039-8 pdf: https://publi2-as.oma.be/record/5626/files/2022_VanNotenetal_HVSR_Powerlaw_Brussels.pdf \n",
    "* Van Noten, K, Lecocq, Buddha Power, B. (2020). HVSR to Virtual Borehole (1.0). Zenodo. https://doi.org/10.5281/zenodo.4276310\n",
    "* Zeckra, M., Van Noten, K., Lecocq, T. Submitted. Sensitivity, Accuracy and Limits of the Lightweight Three-Component SmartSolo Geophone Sensor (5 Hz) for Seismological Applications. _Seismica_. Preprint on: https://doi.org/10.31223/X5F073"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634f4a8",
   "metadata": {},
   "source": [
    "## Modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf58c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import obspy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections as mcoll\n",
    "import matplotlib.gridspec as gridspec\n",
    "from obspy.imaging.scripts.scan import Scanner\n",
    "from obspy.clients.nrl import NRL\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b1144",
   "metadata": {},
   "source": [
    "## Functions used for reading and plotting Geopsy .hv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bcf9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_HV(HV_file):\n",
    "    \"\"\"\n",
    "    Read the .hv output files of Geopsy exported from the HV module.\n",
    "    The definition returns a pandas series of: \n",
    "    Freq, A, A_min, A_max \n",
    "    with \n",
    "    Freq: H/V geometrically averaged over all individual H/V curves (windows)\n",
    "    A0: the H/V amplitude curve\n",
    "    A_min: The H/V amplitude minimum standard deviation.\n",
    "    A_max: The H/V amplitude maximum standard deviation.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(HV_file, delimiter='\\t',names=['Frequency', 'Average', 'Min', 'Max'], comment='#')\n",
    "    Freq = df[\"Frequency\"]\n",
    "    A_min = df['Min']\n",
    "    A = df['Average']\n",
    "    A_max = df['Max']\n",
    "    NaNs = np.isnan(df)\n",
    "    df[NaNs] = 0\n",
    "    return Freq, A, A_min, A_max\n",
    "\n",
    "def get_params_from_HV_curve(HV_file):   \n",
    "    \"\"\"\n",
    "    Find the maximum resonance frequency (f0) and corresponding H/V amplitude (A0) of the H/V curve. \n",
    "    The function returns the resonance frequency and its amplitude and stvd around f0 as \n",
    "    f0_curve, A0_curve, A0_min_curve, A0_max_curve\n",
    "    Alternatively you also can load this from the .hv file.\n",
    "    \"\"\"\n",
    "    Freq, A, A_min, A_max = read_HV(HV_file)\n",
    "    A0_curve = np.max(A)\n",
    "    f0_curve = Freq[np.argmax(A)]\n",
    "    A0_min_curve = np.max(A_min)\n",
    "    A0_max_curve = np.max(A_max)\n",
    "    return f0_curve, A0_curve, A0_min_curve, A0_max_curve\n",
    "\n",
    "def get_params_from_partial_HV_curve(HV_file, range_min , range_max):   \n",
    "    \"\"\"\n",
    "    Find the maximum resonance frequency (f0) and corresponding H/V amplitude (A0) of parts of the H/V curve given in a list of ranges.\n",
    "    range_min and range_max gives the range between the maximum needs to be found.\n",
    "    Default values are 0.2 Hz and 50 Hz, e.g. the default Geopsy values.\n",
    "    The function returns the resonance frequency and its amplitude and stvd around f0 as \n",
    "    f0_curve, A0_curve, A0_min_curve, A0_max_curve\n",
    "    \"\"\"\n",
    "    Freq, A, A_min, A_max = read_HV(HV_file)\n",
    "    \n",
    "    #get the index of all the freq. values in specified zone\n",
    "    position = np.where((Freq>=range_min)&(Freq<=range_max))\n",
    "    \n",
    "    #get the freq. and amplitude values that corresponds with the index\n",
    "    Freqs = Freq[position[0]]\n",
    "    As = A[position[0]]\n",
    "    A_mins = A_min[position[0]]\n",
    "    A_maxs = A_max[position[0]]\n",
    "    \n",
    "    #find max. value index\n",
    "    index_0 = position[0][0]\n",
    "    maxx = np.argmax(As)\n",
    "    \n",
    "    A_range = np.max(As)\n",
    "    A_min_range = np.max(A_mins)\n",
    "    A_max_range = np.max(A_maxs)\n",
    "    f_range = Freqs[index_0 + maxx]  \n",
    "\n",
    "    return f_range, A_range, A_min_range, A_max_range\n",
    "\n",
    "def findf0A0InRanges(freq_ranges,frequency,amplitude):\n",
    "    #description: find the maximum amplitude and corresponding frequency value in every range zone\n",
    "    #input: \n",
    "    #freq_ranges: defined frequency zones to find max. in\n",
    "    #frequency: freq. values (can be interpolated or non-interpolated values)\n",
    "    #amplitude: amplitude values (can be interpolated or non-interpolated values)\n",
    "    #return: list of max. amplitude values (A0) and corresponding freq. values (f0)\n",
    "    \n",
    "    f0 = []\n",
    "    A0 = []\n",
    "    for i in range(0,len(freq_ranges)):\n",
    "        #get the index of all the freq. values in defined zone\n",
    "        position = np.where((frequency>=freq_ranges[i][0])&(frequency<=freq_ranges[i][1]))\n",
    "        #get the freq. and amplitude values that corresponds with the indix\n",
    "        Freq_range = frequency[position]\n",
    "        HVmean_range = amplitude[position]\n",
    "        #find max. values \n",
    "        maxx = np.argmax(HVmean_range)\n",
    "        HVmean_max = round(np.max(HVmean_range),3)\n",
    "        Freq_max = round(Freq_range[maxx],3)\n",
    "\n",
    "        #store f0 and A0 value to list \n",
    "        A0.append(HVmean_max)\n",
    "        f0.append(Freq_max)\n",
    "\n",
    "def get_params_from_HV(HV_file):\n",
    "    \"\"\"\n",
    "    Read all the necessary info that is available in a Geopsy .HV file.\n",
    "    The function returns \n",
    "    f0_avg, f0_win, error, A0, nw_avg, nw_win, f_min, f_max\n",
    "    with\n",
    "    * f0 avg: scanning the average curve and identifying the frequency at which the maximum amplitude occurs (from GEOPSY)\n",
    "    * f0 min: f0_win/stddev (from GEOPSY)\n",
    "    * error: standard deviation on f0 (from GEOPSY)\n",
    "    * A0: maximum amplitude (from GEOPSY)\n",
    "    * nw_avg: number of windows from f0_avg(from GEOPSY)\n",
    "    * nw_win: number of windows (from GEOPSY)\n",
    "    * f min: minimum f0_win.stddev (from GEOPSY)\n",
    "    * f max: maximum f0_win.stddev (from GEOPSY)\n",
    "    \n",
    "    See Github for more info: https://github.com/KoenVanNoten/HVSR_to_virtual_borehole/blob/master/Get%20f0s%20from%20geopsy%20hv%20files.py\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(HV_file, nrows=5, skiprows=1, header=None) #opening the .hv file\n",
    "    rows = [\"n_avg\", \"f0_avg\", \"n_win\", \"f0s\", \"peak_amp\"] #define rows to write in the output file\n",
    "    data = {}\n",
    "    for row in rows:\n",
    "                data[row] = \"\"\n",
    "    delims = [\"=\", \"\\t\", \"=\", \"\\t\", \"\\t\"]\n",
    "    for id2, item in df.iterrows():\n",
    "                XXX = item[0].split(delims[id2])\n",
    "                data[rows[id2]] = np.asarray(XXX[1:], dtype=float).flatten()\n",
    "    data[\"f0_win\"], data[\"f_min\"], data[\"f_max\"] = data[\"f0s\"]\n",
    "    del data[\"f0s\"]\n",
    "\n",
    "    f0_avg = data[\"f0_avg\"][0]\n",
    "    f0_win = data[\"f0_win\"]\n",
    "    error = data[\"f0_win\"] - data[\"f_min\"]\n",
    "    f_min =  data[\"f_min\"]\n",
    "    f_max =  data[\"f_max\"]\n",
    "    A0 = data[\"peak_amp\"][0]\n",
    "    nw_avg = data[\"n_avg\"][0]\n",
    "    nw_win = data[\"n_win\"][0]\n",
    "    \n",
    "    return f0_avg, f0_win, error, A0, nw_avg, nw_win, f_min, f_max\n",
    "\n",
    "def get_interpolated_values_from_HV(HV_file, interpol, f0_win):\n",
    "    \"\"\"\n",
    "    In the default setting, Geopsy only exports 100 frequency-amplitude samples for the computed HVSR curve.\n",
    "    One can increase this number by:\n",
    "       - increasing the logaritmic step count in Geopsy manually (max = 9999)\n",
    "       - by interpolating between the samples and improve the accuracy of picking f0 (this script)\n",
    "    Increasing the samples in Geopsy to 9999 gives the same results, but one might have forgotten to do this while processing\n",
    "    so this interpolation offers a nice twist to solve this.\n",
    "    The part in below executes the interpolation up to 15000 samples (default)\n",
    "    See paper Van Noten et al. (2022) for more information. Same method is applied in the HVSR_to_virtual_borehole module.\n",
    "    Interpol: nr of interpolated samples\n",
    "    f0_win: load the f0 from windows from get_params_from_HV:\n",
    "    \"\"\"\n",
    "    HV_data = np.genfromtxt(HV_file, delimiter='\\t', usecols=(0, 1))\n",
    "    #print(HV_data)\n",
    "    f_orig = HV_data[:, 0] #original frequency data\n",
    "    print(\"nr of samples:\", len(f_orig))\n",
    "    A_orig = HV_data[:, 1] #original amplitude data\n",
    "\n",
    "    func = interp1d(f_orig, A_orig, 'cubic') #IN\n",
    "    f0_interpolated = np.linspace(f_orig[0], f_orig[-1], 15000) #interpolation for 15000 samples\n",
    "    A0_interpolated = func(f0_interpolated) #applying the function for the new Amplitude\n",
    "    A0_int = np.argmax(A0_interpolated)\n",
    "    f0_int = f0_interpolated[A0_int]\n",
    "       \n",
    "    # With the interpolated data new columns can be calculated to compare the interpolated values and the ones provided by Geopsy\n",
    "    f0_int_diff = f0_int - f0_win #difference between f0_interpolated and f0_geopsy\n",
    "    \n",
    "    return f0_int, A0_int, f0_int_diff\n",
    "\n",
    "\n",
    "def write_HVline_to_db(db_HVSR, f_min, f0_win, f0_avg, f0_int, f0_int_diff, error, f_max, A0, nw_win):\n",
    "        \"\"\"\n",
    "        Write all params to the HVSR database using a pandas db.loc function.\n",
    "        \n",
    "        Before using this function, empty columns should be created by the code below: \n",
    "        #### Initializing empty columns that need to be filled from the Geopsy .hv files\n",
    "        for _ in [\"f0_min\", \"f0_win\", \"f0_avg\", \"f0_int\", \"f0_int_diff\", \"error\", \"f0_max\", \"A0\", \"nw\"]:\n",
    "            db_HVSR[_] = 0.\n",
    "        \n",
    "        Then the value of each colomn will be filled in. \n",
    "        \"\"\"\n",
    "        db_HVSR.loc[id, \"f0_min\"] = f_min #f0 min\n",
    "        print(\"f0_min:\", round(f_min,3), \"Hz\")\n",
    "        db_HVSR.loc[id, \"f0_win\"] = f0_win #average f0 computed by averaging the peak f0 values of all individual windows\n",
    "        print(\"f0_win:\", round(f0_win,3), \"Hz\")\n",
    "        db_HVSR.loc[id, \"f0_avg\"] = f0_avg #f0 corresponding to the maximum amplitude of the average f0 - Amplitude curve\n",
    "        print(\"f0_avg:\", round(f0_avg,3), \"Hz\")\n",
    "        db_HVSR.loc[id, \"f0_int\"] = f0_int #interpolated f0 from 15000 samples\n",
    "        print(\"f0_int:\", round(f0_int,3), \"Hz\")\n",
    "        db_HVSR.loc[id, \"f0_int_diff\"] = f0_int_diff #difference between f0_interpolated and f0_win\n",
    "        print (\"f0_ip_diff:\", round(f0_int_diff,3), \"Hz\")\n",
    "        db_HVSR.loc[id, \"error\"] = error #error on f0_win in Geopsy\n",
    "        print(\"error:\", round(error,3), \"Hz\")\n",
    "        db_HVSR.loc[id, \"f0_max\"] = f_max #f0 max\n",
    "        print(\"f0_max:\", round(f_max,3), \"Hz\")\n",
    "        db_HVSR.loc[id, \"A0\"] = A0 #A0\n",
    "        print(\"A0:\", round(A0,3))\n",
    "        db_HVSR.loc[id, \"nw\"] = nw_win #number of windows used to compute f0\n",
    "        print(\"nw:\", int(nw_win), \"windows\")\n",
    "        print('')\n",
    "        \n",
    "        return db_HVSR\n",
    "    \n",
    "def get_paramString():\n",
    "    \"\"\"\n",
    "    Creation of an empty ParamString that can be filled in with optional parameters. \n",
    "    This creates a .log file, similar as when Geopsy is used manually\n",
    "    \"\"\"\n",
    "    ## We create a default PARAM multiline string with the static components for whole processing \n",
    "    ## and formatters for variables\n",
    "    paramsString = '''PARAMETERS_VERSION=1    \\nFROM_TIME_TYPE=Absolute\\nFROM_TIME_TEXT={tStart}\\nTO_TIME_TYPE=Absolute\\nTO_TIME_TEXT={tEnd}\\nREFERENCE=\\nCOMMON_TIME_WINDOWS=false\\nWINDOW_LENGTH_TYPE=Exactly\\nWINDOW_MIN_LENGTH(s)={winLen}\\nWINDOW_MAX_LENGTH(s)={winLen}\\nWINDOW_MAX_COUNT=0\\nWINDOW_MAXIMUM_PRIME_FACTOR=11\\nBAD_SAMPLE_TOLERANCE (s)=0\\nBAD_SAMPLE_GAP (s)=0\\nWINDOW_OVERLAP (%)={overlap}\\nBAD_SAMPLE_THRESHOLD_TYPE={threshold}\\nBAD_SAMPLE_THRESHOLD_VALUE (%)={threshold_pct}\\nANTI-TRIGGERING_ON_RAW_SIGNAL (y/n)=n\\nANTI-TRIGGERING_ON_FILTERED_SIGNAL (y/n)=n\\nSEISMIC_EVENT_TRIGGER (y/n)=n\\nSEISMIC_EVENT_DELAY (s)=-0.1\\nWINDOW_TYPE=Tukey\\nWINDOW_REVERSED=n\\nWINDOW_ALPHA=0.1\\nSMOOTHING_METHOD=Function\\nSMOOTHING_WIDTH_TYPE=Log\\nSMOOTHING_WIDTH={KO}\\nSMOOTHING_SCALE_TYPE=Log\\nSMOOTHING_WINDOW_TYPE=KonnoOhmachi\\nSMOOTHING_WINDOW_REVERSED=n\\nMINIMUM_FREQUENCY={minFreq}\\nMAXIMUM_FREQUENCY={maxFreq}\\nSCALE_TYPE_FREQUENCY=Log\\nSTEP_TYPE_FREQUENCY=Count\\nSAMPLES_NUMBER_FREQUENCY=500\\n#STEP_FREQUENCY=1.00231\\nHIGH_PASS_FREQUENCY=0\\nHORIZONTAL_COMPONENTS={horizontals}\\nHORIZONTAL_AZIMUTH={azimuth}\\nROTATION_STEP={rotSteps}\\nFREQUENCY_WINDOW_REJECTION_MINIMUM_FREQUENCY={rej_min_freq}\\nFREQUENCY_WINDOW_REJECTION_MAXIMUM_FREQUENCY={rej_max_freq}\\nFREQUENCY_WINDOW_REJECTION_STDDEV_FACTOR={rej_stdev}\\nFREQUENCY_WINDOW_REJECTION_MAXIMUM_ITERATIONS={rej_it}\\n'''\n",
    "    return paramsString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd1b5d",
   "metadata": {},
   "source": [
    "## Definitions used for plotting Geopsy .hv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893f5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the HV curve using all data loaded above\n",
    "## standard deviation is a fill_betweenx\n",
    "def plot_HV(Freq, A, A_min, A_max, f0, A0, Amin, Amax, analysis, color):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plot the HV curve from an .hv log file using all necessary params:\n",
    "    Freq, A, A_min, A_max, Amax_f0, Fmax_f0, Amin, Amax, label, color\n",
    "    Label: fill in whatever you want\n",
    "    color: color the H/V curve\n",
    "    Other params see get_params_from_HV() and get_params_from_HV_curve()\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(A, Freq, c=color, label='$f_0$ %s'%analysis, zorder = 0)\n",
    "    plt.fill_betweenx(Freq, A_min,A_max,facecolor='silver', edgecolor=\"k\", alpha=0.3, label = 'error')\n",
    "    print('%s: At %s Hz (f0), the maximum H/V amplitude is %s Â± %s'%(analysis, \n",
    "                                                                     round(f0,2), \n",
    "                                                                     round(A0,1), \n",
    "                                                                     round(Amax-A0,1)))\n",
    "\n",
    "## Compute the depth using the Brussels powerlaw of Van Noten et al. (2022): DOI: https://doi.org/10.1007/s10950-021-10039-8\n",
    "## print the bedrock depth from the f0 value\n",
    "def get_Brussels_powerlaw(f0):\n",
    "    h = 88.631 * np.power(f0,-1.683)\n",
    "    print('    Bedrock at %.2f m depth'%h)\n",
    "\n",
    "### colorline - need for plotting a colored line along the HVSR profile\n",
    "def colorline(x, y, z, cmap=plt.get_cmap('copper'), linewidth=10, alpha=1.0):\n",
    "    \"\"\"\n",
    "    http://nbviewer.ipython.org/github/dpsanders/matplotlib-examples/blob/master/colorline.ipynb\n",
    "    http://matplotlib.org/examples/pylab_examples/multicolored_line.html\n",
    "    Plot a colored line with coordinates x and y\n",
    "    Optionally specify colors in the array z\n",
    "    Optionally specify a colormap, a norm function and a line width\n",
    "    \"\"\"\n",
    "    z = np.asarray(z)\n",
    "    segments = make_segments(x, y)\n",
    "    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, linewidth=linewidth, alpha=alpha)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    return lc\n",
    "\n",
    "\n",
    "### segments - need for plotting a colored line along the HVSR profile\n",
    "def make_segments(x, y):\n",
    "    \"\"\"\"\n",
    "    Create list of line segments from x and y coordinates, in the correct format for LineCollection:\n",
    "    an array of the form   numlines x (points per line) x 2 (x and y) array\n",
    "    \"\"\"\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "## script to plot a virtual borehole from an HV file\n",
    "def HV_to_virtual_borehole(HV_file,ID, Z):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### load HV data\n",
    "    f, A, A_min, A_max = read_HV(HV_file)\n",
    "    \n",
    "    ### Instead of using the output of Geopsy, one can interpolate the entire HVSR curve for 15000 points to improve f0\n",
    "    ### Check get_interpolated_values_from_HV? for info \n",
    "    \n",
    "    if interpolate:\n",
    "        # interpolate for A0\n",
    "        func = interp1d(f, A, 'cubic')\n",
    "        f_ip = np.linspace(f[0], f[len(f) - 1], 15000)\n",
    "        A_ip = func(f_ip)\n",
    "\n",
    "        # interpolate for A_min\n",
    "        func = interp1d(f, A_min, 'cubic')\n",
    "        A_min_ip = func(f_ip)\n",
    "\n",
    "        # interpolate for A_max\n",
    "        func = interp1d(f, A_max, 'cubic')\n",
    "        A_max_ip = func(f_ip)\n",
    "\n",
    "        # overwrite original f, A\n",
    "        A = A_ip\n",
    "        f = f_ip\n",
    "        A_min = A_min_ip\n",
    "        A_max = A_max_ip\n",
    "\n",
    "    A_plot = A * 0\n",
    "\n",
    "    ### Plot the Amplitude - frequency diagram and the virtual borehole\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[12, 1])\n",
    "    plt.suptitle(ID)\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    plt.plot(A,f, linewidth=0.7)\n",
    "    maxx = np.argmax(A)\n",
    "    print(\"A0:\", round(A[maxx],2), \"fmax: \",round(f[maxx],2))\n",
    "    plt.fill_betweenx(f, A_min, A_max, color = 'lightgrey', zorder = -100)\n",
    "    ax0.set_yscale('log')\n",
    "    colorline(A_plot, f, A, cmap='viridis', linewidth=5)\n",
    "    colorbar = colorline(A_plot, f, A, cmap='viridis', linewidth=10)\n",
    "    plt.colorbar(colorbar, label = \"Amplitude\")\n",
    "\n",
    "\n",
    "    #### function to find and plot f0 values from the geopsy files\n",
    "    #A_max = np.max(A0) # find largest amplitude in the geopsy or interpolated values\n",
    "    #A_max = np.where(np.max(A)[0.8,1.2])   # sometimes amplitude is higher at other values dan f0, avoid this by defining a range in which we need to search                           \n",
    "    \n",
    "    ### get the HV info from the HV file\n",
    "    f0_avg, f0_win, error, A0_geopsy, nw_avg, nw_win, f_min, f_max = get_params_from_HV(HV_file)\n",
    " \n",
    "    if interpolate:\n",
    "        ### plot a horizontal line for the average if you want to plot the interpolated f0 value\n",
    "        plt.axhline(y=f[maxx], xmin=0, xmax=20, color='red', linewidth=0.5, zorder=-100)\n",
    "        print(\"f0_ip = \", round(f[maxx], 3))\n",
    "        f0_min = float(f[maxx] - error)\n",
    "        f0_max = float(f[maxx] + error)\n",
    "        \n",
    "        # convert frequency to depth using a powerlaw relation\n",
    "        if depth_conversion == 'powerlaw':\n",
    "            depth = a_pw * np.power(f[maxx], b_pw)\n",
    "        # convert frequency to depth a fixed Vs\n",
    "        if depth_conversion == 'Vs':\n",
    "            depth = Vs / (f[maxx] * 4)\n",
    "            \n",
    "    else:\n",
    "        ### plot a horizontal line for the average if you want to plot the geopsy f0 value\n",
    "        ### still discussion needed if f0_avg or f0_win is the best? fo_ip = f0_avg\n",
    "        plt.axhline(y=f0_avg, xmin=0, xmax=20,color = 'red', linewidth=0.5, zorder = -100)\n",
    "        f0_min = float(f0_avg - error)\n",
    "        f0_max = float(f0_avg + error)\n",
    "        \n",
    "        # convert frequency to depth using a powerlaw relation\n",
    "        if depth_conversion == 'powerlaw':\n",
    "            depth = a_pw * np.power(f0_avg, b_pw)\n",
    "            \n",
    "        # convert frequency to depth a fixed Vs\n",
    "        if depth_conversion == 'Vs':\n",
    "            depth = Vs / (f0_avg * 4)\n",
    "        \n",
    "    ### plot horizontal lines for f0_min and f0_max using the error provided by geopsy\n",
    "    plt.axhline(y=f0_min, xmin=0, xmax=20, color='grey', linewidth=0.5, ls='--', zorder=-100)\n",
    "    plt.axhline(y=f0_max, xmin=0, xmax=20,color = 'grey', linewidth=0.5, ls = '--', zorder = -100)\n",
    "    plt.title(\"$f_0$ int.: %.3f\" % f[maxx] + r\"$\\pm$%.3f\" %error + \"(err)\" + \"; $A_0$: %.2f\" % A0_geopsy, size=10)\n",
    "    plt.ylabel(\"Frequency (Hz)\", fontsize=10)\n",
    "    plt.xlabel(\"Amplitude\", fontsize=10)\n",
    "    if auto_amplitude:\n",
    "        plt.xlim(-1, np.max(A_max))\n",
    "    else:\n",
    "        plt.xlim(-1,manual_amplitude)\n",
    "    plt.ylim(freq[0],freq[1])\n",
    "  \n",
    "    #### Making the virtual borehole in function of depth\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "        \n",
    "    if depth_conversion == 'powerlaw':    \n",
    "        # convert frequency to depth using the powerlaw relation for all frequencies\n",
    "        h = a_pw*np.power(f,b_pw)\n",
    "\n",
    "        #defining the errorbars in the virtual borehole\n",
    "        depth_min = a_pw*np.power(f0_min,b_pw)\n",
    "        depth_max = a_pw*np.power(f0_max,b_pw)\n",
    "\n",
    "    if depth_conversion == 'Vs':\n",
    "        h = Vs / (f * 4)\n",
    "        \n",
    "        #defining the errorbars in the virtual borehole\n",
    "        depth_min =  Vs / (f0_min * 4)\n",
    "        depth_max = Vs / (f0_max * 4)\n",
    "\n",
    "    # calculating absolute depth; Z = altitude of borehole\n",
    "    bedrock = Z - depth\n",
    "    bedrock_min = Z - depth_min\n",
    "    bedrock_max = Z - depth_max\n",
    "    all_depths = Z - h\n",
    "    print (\"Z: \", round(Z,2))\n",
    "    print (\"bedrock at\", round(bedrock,1), \" m (range: \", round(bedrock_min,1), \"m, \", round(bedrock_max,1), \"m)\")\n",
    "\n",
    "    colorline(A_plot, all_depths, A, cmap='viridis', linewidth=50)\n",
    "\n",
    "    plt.ylim(Z+10, Z-depth-20)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.ylabel(\"Altitude bedrock (m TAW)\", fontsize=10)\n",
    "    ax1.axes.get_xaxis().set_ticks([])\n",
    "    ax1.yaxis.set_label_position(\"right\")\n",
    "    ax1.yaxis.tick_right()\n",
    "    plt.axhline(y=bedrock, xmin=0, xmax=20,color = 'red', linewidth=0.8, zorder = 100)\n",
    "    plt.axhline(y=bedrock_min, xmin=0, xmax=20,color = 'black', linewidth=0.8, zorder = 100)\n",
    "    plt.axhline(y=bedrock_max, xmin=0, xmax=20,color = 'black', linewidth=0.8, zorder = 100)\n",
    "    plt.axhline(y=Z, xmin=0, xmax=20,color = 'black', linewidth=0.7, zorder = 100)\n",
    "    plt.annotate('%s'%int(Z) + \" m\", xy=(0.,Z), fontsize = 8)\n",
    "    plt.title(\"Bedrock at %.0f\" % (bedrock) + \" m\", size=10)\n",
    "    \n",
    "## script to plot polarisation data\n",
    "def plot_polarisation_data(in_filespec,ID, limfreq_min,limfreq_max, A0_max):\n",
    "    \"\"\"\n",
    "    The Geopsy output is not intuitive as polar data are plotted in an X (Frequency) - Y (Azimuth) diagram \n",
    "    instead of a 360Â° diagram. This script loads a Geopsy HV rotate module .grid file and \n",
    "    replots it into a more understandable polar plot. It will search the azimuth at which the \n",
    "    maximum resonance frequency occurs. \n",
    "\n",
    "    Data needed:\n",
    "    * .hv.grid file\n",
    "    * ID (node) name\n",
    "    * limfreq_min,limfreq_max: frequency range between the polar plot is made\n",
    "    * A0_max = maximum HV amplitude (can be given or read from the HVSR database)\n",
    "    \n",
    "    Following data is returned:\n",
    "    A_max: maximum amplitude at resonance frequency deduced from the HVSR polarisation analysis\n",
    "    max_freq: Resonance frequency at A_max\n",
    "    max_Azi: Azimuth at which resonance frequency is maximum (deduced from polarisation analysis)\n",
    "    A_min: minimum amplitude at resonance frequency deduced from the HVSR polarisation analysis\n",
    "    min_freq: Azimuth at which resonance frequency is minimal (deduced from polarisation analysis)\n",
    "    min_Azi: Azimuth at which resonance frequency is minimum (deduced from polarisation analysis)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(in_filespec, delimiter=' ', skiprows=0, engine = 'python')\n",
    "    freq = df[\"x\"]\n",
    "    Azi = df[\"y\"]\n",
    "    A = df[\"val\"]\n",
    "\n",
    "    ## Get the rotation step. Default = 10Â° in Geopsy. Can be changed since Geopsy version 3.3.3\n",
    "    groups = df.groupby(Azi)\n",
    "    rotation_classes = len(groups) ## gives the amount of rotation step classes. = 19 for 10Â° steps\n",
    "    rotation_step = int(180/(rotation_classes-1)) ## gives the rotation_step\n",
    "\n",
    "    ### find the polarization by searching for maximum amplitude for each azimuth\n",
    "    Amax = []\n",
    "    freqmax = []\n",
    "    Azimax = []\n",
    "\n",
    "    for i in np.arange(0,180+rotation_step,rotation_step):\n",
    "        index = np.array(np.where((Azi == i)))[0]\n",
    "\n",
    "        ## search for maximum and minimum A0 in a given frequency range\n",
    "        if freq_range:\n",
    "            index_range = []\n",
    "            for ind in index:\n",
    "                if freq[ind] >= f_range[0]:\n",
    "                    if freq[ind] <= f_range[1]:\n",
    "                        index_range.append(ind)\n",
    "            index = index_range\n",
    "\n",
    "        ## find maximum amplitude of each angle (0--> 180) so we later can find the max and min value in this list\n",
    "        ## append the max Amplitude in the i angle\n",
    "        Amax.append(np.max(A[index]))\n",
    "        ## append the frequency corresponding to that amplitude\n",
    "        freqmax.append(freq[index[0] + np.argmax(A[index])])\n",
    "        ## append the angle to a list\n",
    "        Azimax.append(i)\n",
    "        ## find the maximum in the max amplitude list\n",
    "        A_max = np.max(Amax)\n",
    "\n",
    "    #find the minima and maxima (white and red dots in the plot)\n",
    "    max_freq = freqmax[np.argmax(Amax)]\n",
    "    max_Azi = Azimax[np.argmax(Amax)]\n",
    "    A_min = np.min(Amax)\n",
    "    min_freq = freqmax[np.argmin(Amax)]\n",
    "    min_Azi = Azimax[np.argmin(Amax)].transpose()\n",
    "    \n",
    "    if plot_fig:\n",
    "        ####### Let's plot\n",
    "        plt.figure(figsize=(6.5,5))\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "        \n",
    "        ### reshape the amplitude column\n",
    "        A_reshape = A.values.reshape(rotation_classes,int(len(freq)/rotation_classes))\n",
    "\n",
    "        ## define the region where Amplitudes have to be plotted\n",
    "        ## freq = xi; yi = Azimuth; A_reshape is amplitude\n",
    "        xi = np.array([np.geomspace(np.min(freq), np.max(freq), int(len(freq)/rotation_classes)),]*rotation_classes)\n",
    "        yi = np.array([np.arange(0,190,rotation_step),]*int(len(freq)/rotation_classes)).transpose()\n",
    "\n",
    "        ### flip the polar plot to mirror it on the W side\n",
    "        yj = np.array([np.arange(180,370,rotation_step),]*int(len(freq)/rotation_classes)).transpose()\n",
    "\n",
    "        ### for log plots - use fixed amplitudes for whole the dataset or use a flexible A0max for each plot\n",
    "        if A0_max == 0:\n",
    "            plt.pcolormesh(np.deg2rad(yi), np.log(xi), A_reshape, shading='auto', \n",
    "                           cmap='viridis', vmin=0, vmax=np.round(np.max(A), 0), rasterized=True)\n",
    "            plt.pcolormesh(np.deg2rad(yj), np.log(xi), A_reshape, shading='auto', \n",
    "                           cmap='viridis', vmin=0, vmax=np.round(np.max(A), 0),rasterized=True)\n",
    "        else:\n",
    "            plt.pcolormesh(np.deg2rad(yi), np.log(xi), A_reshape, shading='auto', \n",
    "                           cmap='viridis', vmin=0, vmax=np.round(A0_max, 0), rasterized=True)\n",
    "            plt.pcolormesh(np.deg2rad(yj), np.log(xi), A_reshape, shading='auto', \n",
    "                           cmap='viridis', vmin=0, vmax=np.round(A0_max, 0), rasterized=True)\n",
    "\n",
    "        cbar = plt.colorbar(pad = 0.1, format = '%.0f')\n",
    "        cbar.set_label('H/V Amplitude', rotation=90)\n",
    "\n",
    "        if A_max < 10:\n",
    "            format_max = round(A_max,3)\n",
    "        else:\n",
    "            format_max = round(A_max,2)\n",
    "        if A_min < 10:\n",
    "            format_min = round(A_min, 3)\n",
    "        else:\n",
    "            format_min = round(A_min,2)\n",
    "\n",
    "        ### plot the min and maxima (red and white dots)\n",
    "        plt.scatter(np.deg2rad(max_Azi), np.log(max_freq), c='red', edgecolor='black',\n",
    "                    label = \"Max. Ampl. (\"+ str(format_max) + ') at \\n' + str(max_Azi) + 'Â° - '\n",
    "                            + str(max_Azi+180) +'Â° for $f_0$ ' + format(round(max_freq,2), '.2f') + 'Hz', zorder = 3)\n",
    "        plt.scatter(np.deg2rad(min_Azi), np.log(min_freq), c='white', edgecolor='black',\n",
    "                    label = \"Min. Ampl. (\"+ str(format_min) + ') at \\n' + str(min_Azi) + 'Â° - ' + str(min_Azi+180) +'Â° for $f_0$ ' + format(round(min_freq,2), '.2f') + 'Hz', zorder = 3)\n",
    "        plt.scatter(np.deg2rad(max_Azi+180), np.log(max_freq), c='red', edgecolor='black', zorder = 3)\n",
    "        plt.scatter(np.deg2rad(min_Azi+180), np.log(min_freq),c='white', edgecolor='black', zorder = 3)\n",
    "\n",
    "        ### modify the rotational options\n",
    "        ax.set_theta_direction('clockwise')\n",
    "        ax.set_theta_zero_location('N')\n",
    "        ax.set_rlabel_position(0)\n",
    "        ax.text(np.radians(180),np.log(ax.get_rmax()/3.5),'Frequency',fontsize=8,\n",
    "                rotation=90,ha='left',va='center', color= 'white')\n",
    "\n",
    "        # limits of the frequency and modify the ticks of the frequency\n",
    "        if auto_freq:\n",
    "            limfreq_min = round(max_freq,1) - 0.4\n",
    "            limfreq_max = round(max_freq,1) + 0.4\n",
    "\n",
    "        ax.set_rlim(np.log(limfreq_min),np.log(limfreq_max))\n",
    "        pos_list = np.log(np.arange(limfreq_min+0.1,limfreq_max,steps/2))\n",
    "        freq_list = np.round(np.arange(limfreq_min+0.1,limfreq_max,steps),3)\n",
    "        freqs = []\n",
    "        for i in freq_list:\n",
    "            freqs.append(i)\n",
    "            freqs.append('')\n",
    "\n",
    "        ax.yaxis.set_major_locator(ticker.FixedLocator(pos_list))\n",
    "        ax.yaxis.set_minor_locator(ticker.FixedLocator(pos_list+0.1))\n",
    "        ax.yaxis.set_major_formatter(ticker.FixedFormatter((freqs)))\n",
    "\n",
    "        rlabels = ax.get_ymajorticklabels()\n",
    "        for label in rlabels:\n",
    "            label.set_color('white')\n",
    "\n",
    "        # Specify the ticks of the azimuth\n",
    "        ax.set_xticks(np.pi/180. * np.linspace(0,  360, 18, endpoint=False))\n",
    "        ax.yaxis.set_tick_params(labelsize=9)\n",
    "\n",
    "        plt.legend(loc='best', bbox_to_anchor=(-0.4, -0.35, 0.5, 0.5), frameon=False)\n",
    "        plt.grid(linestyle='-.', linewidth=0.2, alpha = 1, zorder = 200, color = 'grey')\n",
    "\n",
    "        # Plot the title\n",
    "        plt.title(\"Resonance frequency polarisation of %s\"%ID, y=1.08)\n",
    "        plt.tight_layout()\n",
    "    if save_fig:\n",
    "        plt.savefig(os.path.join(out_folder, '%s'%ID + '_polarisation.png'))\n",
    "        \n",
    "    return A_max, max_freq, max_Azi,A_min, min_freq, min_Azi\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cebec",
   "metadata": {},
   "source": [
    "### Inventory of IGU-16 HR 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa7ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_IGU_16_HR3C_inv(network, network_code, node_nr, station_lat, station_lon, elevation, site_name, \n",
    "    channel_code, channel_loc, sample_rate):\n",
    "\n",
    "    inv = Inventory(\n",
    "        # We'll add networks later.\n",
    "        networks=[],\n",
    "        source=\"Seismology.be\")\n",
    "\n",
    "    net = Network(\n",
    "        # This is the network code according to the SEED standard - BE_ for nodes\n",
    "        code=network_code,\n",
    "        # A list of stations. We'll add one later.\n",
    "        stations=[],\n",
    "        description=\"SmartSolo 3C IGU16HR nodes - Seismology.be\",\n",
    "        # Start-and end dates when nodes were bought\n",
    "        start_date=obspy.UTCDateTime(2021, 6, 1))\n",
    "\n",
    "    sta = Station(\n",
    "        # This is the station code according to the SEED standard.\n",
    "        code=node_nr,\n",
    "        latitude=station_lat,\n",
    "        longitude=station_lon,\n",
    "        elevation=elevation,\n",
    "        site=Site(name=site_name))\n",
    "    \n",
    "    cha = Channel(\n",
    "        # This is the channel code according to the SEED standard. - # (HH)(DP(Z)(N)(E) for nodes\n",
    "        code=channel_code,\n",
    "        # This is the location code according to the SEED standard.\n",
    "        location_code=channel_loc,\n",
    "        latitude=station_lat,\n",
    "        longitude=station_lon,\n",
    "        elevation=elevation,\n",
    "        depth=0.0,\n",
    "        azimuth=0.0,\n",
    "        dip=-90.0,\n",
    "        sample_rate=sample_rate)\n",
    "\n",
    "    # By default this accesses the NRL online. Offline copies of the NRL can\n",
    "    # also be used instead\n",
    "    nrl = NRL()\n",
    "\n",
    "    # load response from nrl\n",
    "    response_node = nrl.get_response(\n",
    "        datalogger_keys=['DTCC (manufacturers of SmartSolo','SmartSolo IGU-16', '36 dB (64)', '250', 'Linear Phase', 'Off'],\n",
    "        sensor_keys=['DTCC (manuafacturers of SmartSolo)', '5 Hz', 'Rc=1850, Rs=430000'])\n",
    "    # correct typo in gain\n",
    "    response_node.response_stages[0].stage_gain = 76.7\n",
    "    # add additional gain stage for node digitizer\n",
    "    response_node.response_stages[1].stage_gain *= 3355.4428\n",
    "    response_node.recalculate_overall_sensitivity()\n",
    "\n",
    "    # Now tie it all together.\n",
    "    cha.response = response_node\n",
    "    sta.channels.append(cha)\n",
    "    net.stations.append(sta)\n",
    "    inv.networks.append(net)\n",
    "    print(sta.code)\n",
    "\n",
    "    return inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### Get node response:\n",
    "start_date\n",
    "inv = create_inv(\"\",\"BE\", df_loc.loc[node].node_channels,\n",
    "                     df_loc.loc[node].lat, df_loc.loc[node].lon,\n",
    "                     0, df_loc.loc[node].Station,st1[0].stats.channel, \"\", 250)\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5b78f08",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
