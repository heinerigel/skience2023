{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df480ab",
   "metadata": {},
   "source": [
    "# Minionology: HVSR with seismic nodes\n",
    "### Skience2023 practical on HVSR, node installation, applications, Geopsy, continuous data analysis\n",
    "\n",
    "# Continuous HV processing\n",
    "\n",
    "##### Authors:\n",
    "* Koen Van Noten ([@KoenVanNoten](https://github.com/KoenVanNoten))\n",
    "* Martin Zeckra ([@marzeck](https://github.com/marzeck))\n",
    "\n",
    "##### Introduction:\n",
    "In the previous exercises, we had to do the HVSR data analysis manually in Geopsy. HV processing can also be done in an automatic way calling Geopsy from command lines. In this notebook we explain how to use Geopsy's HV module from the Linux terminal (bash scripting) or from windows and how to run the calculations without a GUI. This will help to prepare the processing of longer recording times, as the amount of waveform data that can be handled in Geopsy at once is rather limited. \n",
    "\n",
    "##### Prerequirements:\n",
    "- geopsy (https://www.geopsy.org/): tested with geopsypack-win64-3.4.2\n",
    "\n",
    "All the command line information can be found here: https://www.geopsy.org/wiki/index.php/Geopsy:_Waveform_Command_Line\n",
    "\n",
    "For the continuous processing of the data you have two options: \n",
    "\n",
    "1.) run the first script and load the default geopsy parameter files\n",
    "\n",
    "2.) Create with the bash operation an empty parameter file (i.e. geopsy-hv.params), adapt it to your needs and run everything in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f31119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from obspy import read\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "\n",
    "# run the HVSR Minionology function notebook\n",
    "%run 00_HVSR_Minionology_definitions.ipynb\n",
    "\n",
    "# use ipython notebook in a wider screen\n",
    "from IPython.display import display, HTML # Widen the view\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa3390",
   "metadata": {},
   "source": [
    "## 1. Script to load waveforms and default geopsy parameter analysis\n",
    "In Linux it is enough to load Geopsy using the !geopsy-hv command. \n",
    "\n",
    "In Windows10 the specific user path to the geopsy.exe file needs to be given.\n",
    "\n",
    "#### Commands:\n",
    "Geopsy command lines can be called by the help function: -help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78aff1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: geopsy-hv [OPTIONS] [SIGNAL_FILES]\n",
      "\n",
      "  Calculate H/V spectral ratios and spectra for ambient vibrations.\n",
      "  Sending signal SIGUSR1 prints the current progress.\n",
      "\n",
      "geopsy-hv options: [level=0]\n",
      "  -hv                       HV spectral ratio mode (default).\n",
      "  -spectrum                 Smooth spectra mode.\n",
      "  -rotate                   Produce results in all directions, either HV or\n",
      "                            Spectrum.\n",
      "  -load-windows <FILE>      Load time windows from FILE. Format:\n",
      "                              ### Time Windows ###\n",
      "                              # From time      To time\n",
      "                              YYYYMMddhhmmss.z YYYYMMddhhmmss.z\n",
      "                              ...\n",
      "                              ### End Time Windows ###\n",
      "                            Several instance of this option and wildcards are\n",
      "                            accepted.\n",
      "                            If only one file is provided, the same window set\n",
      "                            is applied to all stations. Else, file names must\n",
      "                            match the station names.(default: automatic\n",
      "                            windows).\n",
      "  -param-example            Output default parameters, template to build a new\n",
      "                            parameter file.\n",
      "  -db                       Database file to process if no signal files are\n",
      "                            imported.\n",
      "  -no-file-key              Skip file content key when loading database (only\n",
      "                            for old database before 2017-09).\n",
      "  -interactive              Allows interactions through stdin/out.\n",
      "  -groups                   Lists the available groups and exits.\n",
      "  -group-leaves             When a group is selected by one of the following\n",
      "                            options, \"leaves\" means: process individualy all\n",
      "                            elementary children. By default, the selected\n",
      "                            folder groups are process in one block. This option\n",
      "                            has no effect if the selected groups are already\n",
      "                            elementary groups  with no children.\n",
      "  -group-id <ID>            Group ID to process. Several entries are allowed.\n",
      "                            If no group is selected, all groups are processed.\n",
      "                            If group with ID contains several children, the\n",
      "                            children are processed.\n",
      "  -group <PATH>             Alias to -group-path.\n",
      "  -group-path <PATH>        Group path to process. Several entries are allowed.\n",
      "                            If no group is selected, all groups are processed.\n",
      "                            If group with PATH contains several children, the\n",
      "                            children are processed.\n",
      "  -group-pattern <REGEXP>   Select for processing all groups whose name matches\n",
      "                            REGEXP. Only one entry is allowed. If no group is\n",
      "                            selected, all groups are processed.\n",
      "  -station-list <STATIONS>  STATIONS is a coma separated list of station names\n",
      "                            to be processed. '-group-*' options are still\n",
      "                            required but only a subset of the group can be\n",
      "                            selected with option '-station-list'.\n",
      "  -coord                    Returns the list of selected stations and their\n",
      "                            coordinates.\n",
      "  -o <FILE>                 Ouput file name (default='a')\n",
      "  -param <PARAM>            Load parameters in PARAM\n",
      "  -set <PARAM>=<VALUE>      Set VALUE to parameter PARAM.\n",
      "  -fix-signal-paths         Only '-db' option is required. Absolute paths\n",
      "                            stored in a '.gpy' can be changed without opening a\n",
      "                            graphical user interface. Useful when moving a\n",
      "                            database to a remote server without X display.\n",
      "  \n",
      "  More options are available. Use '-h all' to display all of them.\n",
      "\n",
      "See also:\n",
      "  More information at http://www.geopsy.org\n",
      "\n",
      "Authors:\n"
     ]
    }
   ],
   "source": [
    "# Linux\n",
    "geopsy_exe = \"geopsy-hv\"\n",
    "\n",
    "# Windows - locate the Geopsypack.win64-3.4.2 folder\n",
    "geopsy_exe = 'C:/Users/koenvn/geopsypack-win64-3.4.2/bin/geopsy-hv.exe'\n",
    "\n",
    "# test the help file\n",
    "!{''.join(geopsy_exe)} -help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0f5cc",
   "metadata": {},
   "source": [
    "We will first play with one node example to understand automation. Let's start with the first node of the Brussels case of exercise 1:\n",
    "\n",
    "Miniseed file: __\"HVSR_ex1_Bru\\Raw_Data\\453000039.1.2022.12.02.09.20.00.000.*.miniseed\"__\n",
    "\n",
    "First:\n",
    "* Analyse the data in Geopsy: \n",
    "* 60s\n",
    "* no trigger\n",
    "* 50% overlap\n",
    "* 40% KO smoothing \n",
    "* output 0.2 - 50 Hz\n",
    "* and save in __HVSR_ex2_Auto\\Analysed__\n",
    "\n",
    "Now you have a BE_00039.hv in __HVSR_ex2_Auto\\Analysed__\n",
    "\n",
    "Then:\n",
    "* call __geopsy.exe__\n",
    "* call the __-hv__ module followed by the __miniseed file__\n",
    "* call the .log file created above by __-param HVSR_ex2_Auto\\Analysed\\BE_00039.log__\n",
    "* store the generated .hv file in a new folder by __-o HVSR_ex2_Auto\\Auto_Analysed__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc6c86f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----WARNING--- Loading parameters----\n",
      "Unable to open file 'HVSR_ex2_Auto\\Analysed\\BE_00039.log' for reading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "geopsy-hv: error loading parameters from 'HVSR_ex2_Auto\\Analysed\\BE_00039.log', see '-param-example'\n"
     ]
    }
   ],
   "source": [
    "!{''.join(geopsy_exe)} -hv \"HVSR_ex1_Bru\\Raw_Data\\453000039.1.2022.12.02.09.20.00.000.*.miniseed\" -param \"HVSR_ex2_Auto\\Analysed\\BE_00039.log\" -o \"HVSR_ex2_Auto\\Auto_Analysed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc872bc",
   "metadata": {},
   "source": [
    "Let's compare the GUI .hv (in Analysed) and the command line .hv (in Auto_analysed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08bd68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the HV plot\n",
    "fig, ax= plt.subplots(figsize=(10,5))\n",
    "    \n",
    "#### read and plot the manual HV example file\n",
    "in_file = r'HVSR_ex2_Auto\\Analysed\\BE_00039.hv'\n",
    "\n",
    "Freq, A, A_min, A_max = read_HV(in_file) # Get the HV profile\n",
    "f0_curve, A0_curve, A0_min_curve, A0_max_curve = get_params_from_HV_curve(in_file) # Get the HV params from the HV plot\n",
    "plot_HV(Freq, A, A_min, A_max, f0_curve, A0_curve, A0_min_curve, A0_max_curve, 'Manual', 'Blue') #plot the curve\n",
    "get_Brussels_powerlaw(f0_curve) # print the bedrock depth\n",
    "\n",
    "#### read and plot the auto HV example file\n",
    "auto_file = r'HVSR_ex2_Auto\\Auto_Analysed\\BE_00039.hv'\n",
    "\n",
    "Freq, A, A_min, A_max = read_HV(auto_file) # Get the HV profile\n",
    "f0_curve, A0_curve, A0_min_curve, A0_max_curve = get_params_from_HV_curve(auto_file) # Get the HV params from the HV plot\n",
    "plot_HV(Freq, A, A_min, A_max, f0_curve, A0_curve, A0_min_curve, A0_max_curve, 'Automatic', 'Red') #plot the curve\n",
    "get_Brussels_powerlaw(f0_curve) # print the bedrock depth\n",
    "\n",
    "# Params\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('H/V amplitude', fontsize = 14)\n",
    "plt.ylabel('Frequency ([Hz])', fontsize = 14)\n",
    "plt.legend()\n",
    "plt.title(os.path.splitext(os.path.split(in_file)[1])[0], fontsize = 14)\n",
    "plt.grid(ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a6474",
   "metadata": {},
   "source": [
    "__Are you happy with his curve?__ \n",
    "No. Why not? Because all windows were accepted in the automatic solution. \n",
    "\n",
    "Now try to do the same exercise by using a __Relative Treshold of 70%__, Reject time windows and clear the grayed curved (see exercise 1). Save this log and .hv file and compare again with the automatic solution. \n",
    "\n",
    "The question now is how to force the automatic solution so that is resembles the manual solution. In Geopsy, you can use the Frequency Rejection of Cox et al. (2020) to autoreject the bad windows. Play with the params to get the HV curve simiar to the manual solution, e.g.:\n",
    "* min. freq.: 0.50 Hz\n",
    "* max. freq.: 50 Hz\n",
    "* stdv v: 2.50\n",
    "* nr iterations: 500\n",
    "\n",
    "More information on this auto rejection is explained here by B. Cox: _As you may recall from my 2020 paper, __n is the number of standard deviations__. So, when using n = 2 we are incorporating approximately 95% of the f0 values obtained from the various time windows. When using n = 1 we are incorporating only about 68% of the f0 values from the various time windows. The choice of n depends on how noisy the site is. If the site is very noisy, there will be a lot of near-receiver noise sources that are imparting energy to the sensor that is not traveling upward through the ground. These contaminated time windows need to be rejected. In this case, one would need to set n lower to reject more of the contaminated windows. However, setting n too low will result in good windows being rejected, which will bias your f0 sigma values to low estimates. The median value of f0 may or may not be affected very much, but the sigma of f0 will definitely be affected. I typically start by using n = 2 and then decrease n if it looks like I am still not getting rid of some of the outlying f0 values. This is subjective, but I feel it is a good way to do it. __The STA / LTA anti-triggering is doing something completely different__. It is simply looking at which time windows have relatively high amplitudes and rejecting them. This is based on the premise that near-receiver sources of energy will have high amplitudes. In many cases they do. But not always. I found that the STA / LTA method was difficult to use and could not produce results that were statistically based. Thatâ€™s why I developed the FWA approach._ : https://www.geopsy.org/forum/viewtopic.php?t=535"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8277fce",
   "metadata": {},
   "source": [
    "## 2. Create a parameter file to your needs and run Geopsy from command\n",
    "\n",
    "Now we will try a more automated way. In this script, the HV .log file is first loaded by default parameters. Then, we will update those parameters depending on the personal needs/dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We create a default PARAM multiline string with the static components for whole processing \n",
    "## and formatters for variables\n",
    "paramsString = '''\\\n",
    "PARAMETERS_VERSION=1    \n",
    "FROM_TIME_TYPE=Absolute\n",
    "FROM_TIME_TEXT={tStart}\n",
    "TO_TIME_TYPE=Absolute\n",
    "TO_TIME_TEXT={tEnd}\n",
    "REFERENCE=\n",
    "COMMON_TIME_WINDOWS=false\n",
    "WINDOW_LENGTH_TYPE=Exactly\n",
    "WINDOW_MIN_LENGTH(s)={winLen}\n",
    "WINDOW_MAX_LENGTH(s)={winLen}\n",
    "WINDOW_MAX_COUNT=0\n",
    "WINDOW_MAXIMUM_PRIME_FACTOR=11\n",
    "BAD_SAMPLE_TOLERANCE (s)=0\n",
    "BAD_SAMPLE_GAP (s)=0\n",
    "WINDOW_OVERLAP (%)={overlap}\n",
    "BAD_SAMPLE_THRESHOLD_TYPE={threshold}\n",
    "BAD_SAMPLE_THRESHOLD_VALUE (%)={threshold_pct}\n",
    "ANTI-TRIGGERING_ON_RAW_SIGNAL (y/n)=n\n",
    "ANTI-TRIGGERING_ON_FILTERED_SIGNAL (y/n)=n\n",
    "SEISMIC_EVENT_TRIGGER (y/n)=n\n",
    "SEISMIC_EVENT_DELAY (s)=-0.1\n",
    "WINDOW_TYPE=Tukey\n",
    "WINDOW_REVERSED=n\n",
    "WINDOW_ALPHA=0.1\n",
    "SMOOTHING_METHOD=Function\n",
    "SMOOTHING_WIDTH_TYPE=Log\n",
    "SMOOTHING_WIDTH={KO}\n",
    "SMOOTHING_SCALE_TYPE=Log\n",
    "SMOOTHING_WINDOW_TYPE=KonnoOhmachi\n",
    "SMOOTHING_WINDOW_REVERSED=n\n",
    "MINIMUM_FREQUENCY={minFreq}\n",
    "MAXIMUM_FREQUENCY={maxFreq}\n",
    "SCALE_TYPE_FREQUENCY=Log\n",
    "STEP_TYPE_FREQUENCY=Count\n",
    "SAMPLES_NUMBER_FREQUENCY=500\n",
    "#STEP_FREQUENCY=1.00231\n",
    "HIGH_PASS_FREQUENCY=0\n",
    "HORIZONTAL_COMPONENTS={horizontals}\n",
    "HORIZONTAL_AZIMUTH={azimuth}\n",
    "ROTATION_STEP={rotSteps}\n",
    "FREQUENCY_WINDOW_REJECTION_MINIMUM_FREQUENCY={rej_min_freq}\n",
    "FREQUENCY_WINDOW_REJECTION_MAXIMUM_FREQUENCY={rej_max_freq}\n",
    "FREQUENCY_WINDOW_REJECTION_STDDEV_FACTOR={rej_stdev}\n",
    "FREQUENCY_WINDOW_REJECTION_MAXIMUM_ITERATIONS={rej_it}\n",
    "'''\n",
    "paramsString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd10ed",
   "metadata": {},
   "source": [
    "Or load the paramString from the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0364391",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsString = get_paramString()\n",
    "paramsString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d76aaa",
   "metadata": {},
   "source": [
    "There are several params that are variable. We adapt the PARAMS for the whole dataset we want to analyse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9342a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window length for each HV curve\n",
    "time_window_len = 60. # [s] standard 60 or 120s\n",
    "\n",
    "#overlapping windows\n",
    "win_overlap = 50\n",
    "\n",
    "# threshold and percentage\n",
    "threshold = 'RelativeSampleThreshold'\n",
    "threshold_pct = 0.7\n",
    "\n",
    "#Smoothing (in digits)\n",
    "KO = 0.4\n",
    "\n",
    "# lower frequency bound\n",
    "min_freq = 0.2 # [Hz]\n",
    "\n",
    "# upper frequency bound\n",
    "max_freq = 50 # [Hz]\n",
    "\n",
    "# how to calculate horizontals (Squared, Energy, Azimuth, Geometric)\n",
    "horizontals_method = 'Squared' # standard 'Squared'\n",
    "\n",
    "##HORIZONTAL_AZIMUTH is used only when HORIZONTAL_COMPONENTS== 'Azimuth'\n",
    "azimuth = 0\n",
    "\n",
    "# in case you want run the HV rotate module (see exercise 4)\n",
    "want_rotation = True # True, False\n",
    "rotation_steps = 10 # [degree]\n",
    "\n",
    "## Using the Cox et al. 2020 filtering - doesn't work - bug in Geopsy:\n",
    "## https://www.geopsy.org/forum/viewtopic.php?t=566&sid=79274e47c5fc734075d1aa895fe8021f\n",
    "\n",
    "#FREQUENCY_WINDOW_REJECTION_MINIMUM_FREQUENCY\n",
    "rej_min_freq = 0.5\n",
    "#FREQUENCY_WINDOW_REJECTION_MAXIMUM_FREQUENCY\n",
    "rej_max_freq = 50\n",
    "#FREQUENCY_WINDOW_REJECTION_STDDEV_FACTOR\n",
    "rej_stdev = 1.8\n",
    "#FREQUENCY_WINDOW_REJECTION_MAXIMUM_ITERATIONS\n",
    "rej_it = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e711f8",
   "metadata": {},
   "source": [
    "Now the parameters are given, it is time to fill in these parameters in the PARAM file. We will use Obspy for getting the begin and endtime from the seismic data. This can easily be done by reading tr.stats.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d718a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally some seismology and Obspy\n",
    "\n",
    "from obspy import read\n",
    "from obspy.core.trace import Stats\n",
    "\n",
    "#wf = r'HVSR_ex1_Br\\\\Raw_Data\\\\453000039.1.2022.12.02.09.20.00.000.*.miniseed'\n",
    "#wf = r'HVSR_ex1_Br\\\\Raw_Data\\\\453000039.1.2022.12.02.09.20.00.000.*.miniseed'\n",
    "\n",
    "st = read(r'HVSR_ex1_Bru\\\\Raw_Data\\\\453000039.1.2022.12.02.09.20.00.000.*.miniseed')\n",
    "#st = read(wf)\n",
    "\n",
    "tr = st[0]\n",
    "time = tr.stats.starttime\n",
    "tStart = '%s%02d%02d%02d%02d%#05.2f'%(time.year, time.month, time.day, time.hour, time.minute, time.second)\n",
    "endtime = tr.stats.endtime\n",
    "tEnd = '%s%02d%02d%02d%02d%#05.2f'%(endtime.year, endtime.month, endtime.day, endtime.hour, endtime.minute, endtime.second)\n",
    "\n",
    "# adapt an auto-PARAM file with the given parameters so that for each processing loop the same param is used\n",
    "with open('geopsy-hv-auto.params', 'w') as f:\n",
    "            f.write(paramsString.format(\n",
    "                # Select start and end time from waveform\n",
    "                tStart=tStart,\n",
    "                # Select end time from waveform\n",
    "                tEnd=tEnd,\n",
    "                # Adapt the parameters of previously chosen parameters \n",
    "                threshold=threshold,\n",
    "                threshold_pct=threshold_pct,\n",
    "                KO=KO,\n",
    "                winLen=time_window_len,\n",
    "                overlap=win_overlap,\n",
    "                minFreq=min_freq,\n",
    "                maxFreq=max_freq,\n",
    "                horizontals=horizontals_method,\n",
    "                azimuth=azimuth,\n",
    "                rotSteps=rotation_steps,\n",
    "                rej_min_freq=rej_min_freq, \n",
    "                rej_max_freq=rej_max_freq, \n",
    "                rej_stdev=rej_stdev,\n",
    "                rej_it = rej_it\n",
    "                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b270a1",
   "metadata": {},
   "source": [
    "Now the param is changed and loaded as _geopsy-hv-auto.params_ file, launch Geopsy again but now with the -param geopsy-hv-auto.params parameter (and not by a .log file as in the previous example) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6074a1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!{''.join(geopsy_exe)} -hv \"HVSR_ex1_Bru\\Raw_Data\\453000039.1.2022.12.02.09.20.00.000.*.miniseed\" -param geopsy-hv-auto.params -o \"HVSR_ex2_Auto\\Auto_Analysed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebd85d",
   "metadata": {},
   "source": [
    "Let's compare again the manual .hv (Geopsy) with the automatic .hv file (from command with predefined user params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f813c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the HV plot\n",
    "fig, ax= plt.subplots(figsize=(10,5))\n",
    "    \n",
    "#### read and plot the manual HV example file\n",
    "in_file = r'HVSR_ex2_Auto\\Analysed\\BE_00039.hv'\n",
    "\n",
    "Freq, A, A_min, A_max = read_HV(in_file) # Get the HV profile\n",
    "f0_curve, A0_curve, A0_min_curve, A0_max_curve = get_params_from_HV_curve(in_file) # Get the HV params from the HV plot\n",
    "plot_HV(Freq, A, A_min, A_max, f0_curve, A0_curve, A0_min_curve, A0_max_curve, 'Manual', 'Blue') #plot the curve\n",
    "get_Brussels_powerlaw(f0_curve) # print the bedrock depth\n",
    "\n",
    "#### read and plot the auto HV example file\n",
    "auto_file = r'HVSR_ex2_Auto\\Auto_Analysed\\BE_00039.hv'\n",
    "\n",
    "Freq, A, A_min, A_max = read_HV(auto_file) # Get the HV profile\n",
    "f0_curve, A0_curve, A0_min_curve, A0_max_curve = get_params_from_HV_curve(auto_file) # Get the HV params from the HV plot\n",
    "plot_HV(Freq, A, A_min, A_max, f0_curve, A0_curve, A0_min_curve, A0_max_curve, 'Automatic', 'Red') #plot the curve\n",
    "\n",
    "get_Brussels_powerlaw(f0_curve) # print the bedrock depth\n",
    "\n",
    "# Params\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('H/V amplitude', fontsize = 14)\n",
    "plt.ylabel('Frequency ([Hz])', fontsize = 14)\n",
    "plt.legend()\n",
    "plt.title(os.path.splitext(os.path.split(in_file)[1])[0], fontsize = 14)\n",
    "plt.grid(ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca46e7",
   "metadata": {},
   "source": [
    "* __Evaluate__ the result. \n",
    "* Is there still a difference between the manual and auto solution? \n",
    "* Which is the difference? \n",
    "* Evaluate the difference in the shape of the curve, the f0 and HV amplitude values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0795ce",
   "metadata": {},
   "source": [
    "## 3. Loop over a waveform datafolder for HVSR batch processing\n",
    "Now we understand how to call Geopsy from the command line, last step is develop a code that can loop over:\n",
    "* __3.1.__ a set of waveforms and autoprocess the HVSR of each waveform. This exercise is interesting to autoprocess many datarecordings.  \n",
    "* __3.2.__ one waveform with multiple hours or days of data and autoprocess each hour/day of data\n",
    "\n",
    "3.1 is interesting to autoprocess many datarecordings but 3.2. is particularly interesting as the variability of the H/V curve can be investigated over time, with changing weather/noise conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c47a6",
   "metadata": {},
   "source": [
    "### 3.1. Loop over a folder with waveforms and autoprocess the HV-curve\n",
    "As you understand now the processing as explained in point 2, I'll let you play with the commands yourself. Try to create a param file (or use the one in section 2) and autoprocess the example files in folder __HVSR_ex1_Bru\\Raw_Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the param file, or use the param file of above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60682d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over a waveform folder using glob.glob\n",
    "# select the waveforms (E, N, Z) \n",
    "# execute the geopsy command line\n",
    "# save the resulting .hv file in a dedicated folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226e45c",
   "metadata": {},
   "source": [
    "### 3.2. Loop over one waveform, split the data in hourly chunks and autoprocess the HV-curve\n",
    "This exercise is more tricky as we need to run over different overlapping tStart and tEnd times, adapt the PARAM file (ParamsString) and run Geopsy for each (half)hour (or day, or whatever timing you want) of data. We will play with node 0617 (\"453000617.1.2022.12.02.08.49.00.000.*.miniseed\"), which was the node recording the longest in Brussels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall processing lengths (time for which we compute the total HV-curve)\n",
    "#process_len = 3600. # [s] standard 1 hour\n",
    "process_len = 1800. # [s] 0.5 hour\n",
    "\n",
    "# window length for each HV curve\n",
    "time_window_len = 60. # [s] standard 60 or 120s\n",
    "\n",
    "#overlapping windows\n",
    "win_overlap = 50\n",
    "\n",
    "# threshold and percentage\n",
    "threshold = 'RelativeSampleThreshold'\n",
    "threshold_pct = 0.7\n",
    "\n",
    "#Smoothing (in digits)\n",
    "KO = 0.4\n",
    "\n",
    "# lower frequency bound\n",
    "min_freq = 0.5 # [Hz]\n",
    "\n",
    "# upper frequency bound\n",
    "max_freq = 50 # [Hz]\n",
    "\n",
    "# how to calculate horizontals (Squared, Energy, Azimuth, Geometric)\n",
    "horizontals_method = 'Squared' # standard 'Squared'\n",
    "\n",
    "##HORIZONTAL_AZIMUTH is used only when HORIZONTAL_COMPONENTS== 'Azimuth'\n",
    "azimuth = 0\n",
    "\n",
    "# in case you want run the HV rotate module (see exercise 4)\n",
    "want_rotation = False # True, False\n",
    "rotation_steps = 10 # [degree]\n",
    "\n",
    "# Using the Cox et al. 2020 filtering \n",
    "#FREQUENCY_WINDOW_REJECTION_MINIMUM_FREQUENCY\n",
    "rej_min_freq = 0.5\n",
    "#FREQUENCY_WINDOW_REJECTION_MAXIMUM_FREQUENCY\n",
    "rej_max_freq = 50\n",
    "#FREQUENCY_WINDOW_REJECTION_STDDEV_FACTOR\n",
    "rej_stdev = 1.8\n",
    "#FREQUENCY_WINDOW_REJECTION_MAXIMUM_ITERATIONS\n",
    "rej_it = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ddf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give waveform\n",
    "#wf = \"HVSR_ex1_Bru\\\\Raw_Data\\\\453000617.1.2022.12.02.08.49.00.000.*.miniseed\"\n",
    "wf = \"HVSR_ex1_Bru\\\\Raw_Data\\\\453001013.1.2022.12.02.09.04.00.000.*.miniseed\"\n",
    "node_ID = os.path.split(wf)[-1].split('.')[0] # Better to have BE.00617 in the folder name or the full node ID name??\n",
    "print(node_ID)\n",
    "\n",
    "# Give outputfolder where to save the .hv files\n",
    "output_folder = 'HVSR_ex2_Auto/Auto_Analysed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e6e6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get the station info\n",
    "st = read(wf)\n",
    "tr = st[0]\n",
    "start = tr.stats.starttime\n",
    "end = tr.stats.endtime\n",
    "station = '%s_%s'%(tr.stats.network, tr.stats.station)\n",
    "print('station: %s'%station)\n",
    "\n",
    "delta = end-start\n",
    "print(\"start: %s\"%start)\n",
    "print(\"end: %s\"%end) \n",
    "print(\"We will get %s .hv files of %ss length out of the stream\"%(int(delta/process_len), process_len))\n",
    "\n",
    "for i in np.arange(start, end, process_len):\n",
    "        time = i\n",
    "        print(time)\n",
    "        tStart = '%s%02d%02d%02d%02d%#05.2f'%(time.year, time.month, time.day, time.hour, time.minute, time.second)\n",
    "        tStart_hv = '%s%02d%02d%02d%02d%#02d'%(time.year, time.month, time.day, time.hour, time.minute, time.second)\n",
    "        endtime = time + process_len\n",
    "        tEnd = '%s%02d%02d%02d%02d%#05.2f'%(endtime.year, endtime.month, endtime.day, endtime.hour, endtime.minute, endtime.second)\n",
    "        \n",
    "        # get the empty auto-paramString\n",
    "        paramsString = get_paramString()\n",
    "        \n",
    "        # adapt an auto-PARAM file with the given parameters so that for each processing loop the same param is used\n",
    "        with open('geopsy-hv-auto.params', 'w') as f:\n",
    "            f.write(paramsString.format(\n",
    "                # Select start and end time from waveform\n",
    "                tStart=tStart,\n",
    "                # Select end time from waveform\n",
    "                tEnd=tEnd,\n",
    "                # Adapt the parameters of previously chosen parameters \n",
    "                threshold=threshold,\n",
    "                threshold_pct=threshold_pct,\n",
    "                KO=KO,\n",
    "                winLen=time_window_len,\n",
    "                overlap=win_overlap,\n",
    "                minFreq=min_freq,\n",
    "                maxFreq=max_freq,\n",
    "                horizontals=horizontals_method,\n",
    "                azimuth=azimuth,\n",
    "                rotSteps=rotation_steps,\n",
    "                rej_min_freq=rej_min_freq, \n",
    "                rej_max_freq=rej_max_freq, \n",
    "                rej_stdev=rej_stdev,\n",
    "                rej_it = rej_it\n",
    "                ))\n",
    "        \n",
    "        ### Make a folder for each station output\n",
    "        os.makedirs(output_folder+node_ID, exist_ok=True)\n",
    "        out_folder = ''.join(output_folder+node_ID)\n",
    "        \n",
    "        ### Run geopsy for each step in the loop\n",
    "        !{''.join(geopsy_exe)} -hv {''.join(wf)} -param geopsy-hv-auto.params -o {''.join(output_folder+node_ID)}\n",
    "        \n",
    "        ### Rename the .hv output file and the .log to save a unique files for each processed process_len\n",
    "        ### saving the .log files is useful as these can be loaded in Geopsy to manually check the processed data \n",
    "        os.renames(os.path.join(output_folder, '{0}/{1}.hv'.format(node_ID, station)), os.path.join(output_folder, '{0}/{1}.{2}.hv'.format(node_ID, station, tStart_hv)))\n",
    "        os.renames(os.path.join(output_folder, '{0}/{1}.log'.format(node_ID, station)), os.path.join(output_folder, '{0}/{1}.{2}.log'.format(node_ID, station, tStart_hv)))\n",
    "\n",
    "        # if want_rotation is selected, also the HV rotate module will be executed and stored in the outfolder  \n",
    "        if want_rotation:\n",
    "            \n",
    "            # run the geopsy rotation\n",
    "            !{''.join(geopsy_exe)} -rotate {''.join(wf)} -param geopsy-hv-auto.params -o {''.join(output_folder+node_ID)}\n",
    "            \n",
    "            ### Rename the .hv.grid output file\n",
    "            os.renames(os.path.join(output_folder, '{0}/{1}.hv'.format(node_ID, station)), os.path.join(output_folder, '{0}/{1}.{2}.grid'.format(node_ID, station, tStart_hv)))\n",
    "            \n",
    "        print('**********************************')    \n",
    "\n",
    "print('Job Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9e5bd",
   "metadata": {},
   "source": [
    "## 4. Visualising auto results\n",
    "The final step consists of visualing the auto-generated .hv files with time. Try to plot the .hv results from each node through time. Loop over the .hv files with glob.glob and read in the data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d447e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the output folder containing all subfolders with continuous hv files\n",
    "output_folder = 'HVSR_ex2_Auto/Auto_Analysed/'\n",
    "\n",
    "###################################################################\"\"\n",
    "# create the continuous HV plot\n",
    "fig, ax1= plt.subplots(figsize=(10,5))\n",
    "\n",
    "# loop over the subfolders\n",
    "folders = glob.glob(\"%s/*/\"%output_folder, recursive = True)\n",
    "for i in folders:\n",
    "    \n",
    "    f0_wins = []\n",
    "    f0_avgs = []\n",
    "    A0s = []\n",
    "    times = []\n",
    "    errors_min, errors_max = [], []\n",
    "    HV_files = glob.glob('%s/*.hv'%i)\n",
    "    # loop over the HV files\n",
    "    for i in HV_files:\n",
    "        node_ID = os.path.split(i)[-1].split('.')[0]\n",
    "        # read the time from the HV name\n",
    "        time = os.path.split(i)[1].split('.')[1]\n",
    "        year = time[0:4]\n",
    "        d = datetime.datetime(int(time[0:4]),int(time[4:6]), int(time[6:8]), int(time[8:10]), int(time[10:12]), int(time[12:14]))\n",
    "        print(i, d)\n",
    "\n",
    "        f0_avg, f0_win, error, A0, nw_avg, nw_win, f_min, f_max = get_params_from_HV(i)\n",
    "\n",
    "        f0_avgs.append(f0_avg)\n",
    "        A0s.append(A0)\n",
    "        f0_wins.append(f0_win)\n",
    "        errors_min.append(f0_avg-f_min)\n",
    "        errors_max.append(f_max-f0_avg)\n",
    "        times.append(d)\n",
    "\n",
    "    plt.scatter(times, f0_avgs, ls='-', label = node_ID)    \n",
    "    plt.errorbar(times, f0_avgs, xerr=None, yerr = (errors_min, errors_max), c='grey',  alpha=0.5, zorder=-1)   \n",
    "    ax1.set_yscale('log')\n",
    "    ax1.yaxis.set_minor_formatter(mticker.ScalarFormatter())\n",
    "    ax1.yaxis.set_major_formatter(mticker.ScalarFormatter())\n",
    "    ax1.set_xlabel('Datetime', fontsize = 14)\n",
    "    ax1.set_ylabel('Frequency [Hz]', fontsize = 14)\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 0), loc=\"lower left\", borderaxespad=0, ncol=1)\n",
    "    ax1.grid(ls='--', axis='y', which='both')\n",
    "    plt.subplots_adjust(hspace=0.1)\n",
    "    ax1.tick_params(labelbottom=True)\n",
    "    plt.title('HVSR variability', fontsize = 14)\n",
    "\n",
    "    #Format the xaxis date\n",
    "    from matplotlib.dates import DateFormatter, DayLocator, HourLocator\n",
    "\n",
    "    ax1.xaxis.set_major_locator(HourLocator())\n",
    "    ax1.xaxis.set_major_formatter(DateFormatter(\"%H:%M\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e109e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee76bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
